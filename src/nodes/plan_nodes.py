from idlelib.undo import Command

from langchain.agents import create_agent
from langchain_core.output_parsers import JsonOutputParser
from langchain_core.prompts import PromptTemplate
from datetime import datetime
from langgraph.errors import GraphInterrupt
import time
import traceback

from src.config.llm import q_max, get_gpt_model, mt_llm
from src.graph_state import AgentState, Plan
from src.prompt.plan import planner_prompt_template
from src.tools import check_low_star_merchant, check_sensitive_merchant
from src.models.execution_result import (
    StepExecutionResult,
    StepStatus,
    ToolCall,
    PlanExecutionSummary
)


def planning_node(state: AgentState):
    """ç”Ÿæˆæ‰§è¡Œè®¡åˆ’ - æ ¹æ®intentåŠ¨æ€é€‰æ‹©prompt"""
    from langchain_core.messages import AIMessage
    from src.config.sop_loader import get_sop_loader
    
    faq_query = state['faq_query']
    intent = state.get('intent', 'default')
    
    # â­ ä»SOPLoaderè·å–planning prompt
    sop_loader = get_sop_loader()
    prompt_template_text = sop_loader.get_planning_prompt(intent)
    
    # å¦‚æœæ²¡æœ‰ä¸“ä¸špromptï¼Œé™çº§åˆ°é€šç”¨prompt
    if not prompt_template_text:
        prompt_template_text = planner_prompt_template
        print(f"[Planning] Using default prompt (no custom for '{intent}')")
    else:
        print(f"[Planning] Using custom prompt for '{intent}'")
    
    # å‡†å¤‡parserå’Œæ ¼å¼åŒ–
    plan_parser = JsonOutputParser(pydantic_object=Plan)
    format_instructions = plan_parser.get_format_instructions()
    
    final_prompt = prompt_template_text.format(
        query=faq_query,
        format_instructions=format_instructions
    )
    
    # è°ƒç”¨LLM
    planner_prompt = PromptTemplate(
        template="{text}",
        input_variables=["text"]
    )
    chain = planner_prompt | q_max | JsonOutputParser()
    result = chain.invoke({"text": final_prompt})
    
    steps = result.get('steps', [])
    
    # ğŸ“ æ·»åŠ è®¡åˆ’ç”Ÿæˆæ¶ˆæ¯
    plan_message = AIMessage(
        content=f"ğŸ“‹ [{intent}] å·²ç”Ÿæˆæ‰§è¡Œè®¡åˆ’ï¼Œå…±{len(steps)}ä¸ªæ­¥éª¤:\n" + 
                "\n".join([f"{i+1}. {step}" for i, step in enumerate(steps)])
    )
    
    return {
        "plan": steps,
        "current_step": 0,
        "messages": [plan_message]
    }


def plan_executor_node(state: AgentState):
    """å¢å¼ºç‰ˆè®¡åˆ’æ‰§è¡ŒèŠ‚ç‚¹ - æ”¯æŒHuman-in-the-Loop"""
    plan = state.get("plan", [])
    current_step = state.get("current_step", 0)
    
    # æ£€æŸ¥æ˜¯å¦å·²å®Œæˆæ‰€æœ‰æ­¥éª¤
    if current_step >= len(plan):
        print(f"[PlanExecutor] æ‰€æœ‰æ­¥éª¤å·²å®Œæˆ")
        return finalize_execution(state)
    
    step_description = plan[current_step]
    
    # åˆå§‹åŒ–æ­¥éª¤æ‰§è¡Œç»“æœ
    step_result = StepExecutionResult(
        step_index=current_step,
        step_description=step_description,
        status=StepStatus.RUNNING,
        start_time=datetime.now(),
        input_context={
            "query": state.get("query"),
            "previous_steps": len(state.get("step_results", [])),
            "faq_context": state.get("faq_response")
        }
    )
    
    # ğŸ“ æ·»åŠ æ¶ˆæ¯
    from langchain_core.messages import AIMessage
    messages_to_add = []
    
    # â­ æ£€æŸ¥æ˜¯å¦æ˜¯æ¢å¤æ‰§è¡Œï¼ˆä»ask_humanè¿”å›ï¼‰
    # é€šè¿‡æ£€æŸ¥messagesä¸­çš„æœ€åä¸€æ¡HumanMessageæ¥åˆ¤æ–­
    messages = state.get("messages", [])
    user_input = None
    
    if messages and len(messages) >= 2:
        # æ£€æŸ¥æœ€åä¸¤æ¡æ¶ˆæ¯æ˜¯å¦æ˜¯ AIMessage(é—®é¢˜) + HumanMessage(å›å¤)
        if (messages[-2].__class__.__name__ == "AIMessage" and 
            "â¸ï¸" in messages[-2].content and
            messages[-1].__class__.__name__ == "HumanMessage"):
            user_input = messages[-1].content
            print(f"[Executor] æ£€æµ‹åˆ°ç”¨æˆ·å›å¤: {user_input}")
            
            # æ·»åŠ æ¢å¤æ¶ˆæ¯
            resume_message = AIMessage(
                content=f"â–¶ï¸ æ”¶åˆ°æ‚¨çš„å›å¤ï¼Œç»§ç»­æ‰§è¡Œæ­¥éª¤ {current_step + 1}"
            )
            messages_to_add.append(resume_message)
    
    if not user_input:
        # é¦–æ¬¡æ‰§è¡Œæ­¤æ­¥éª¤ï¼Œæ·»åŠ å¼€å§‹æ¶ˆæ¯
        start_message = AIMessage(
            content=f"ğŸ”„ å¼€å§‹æ‰§è¡Œæ­¥éª¤ {current_step + 1}/{len(plan)}: {step_description}"
        )
        messages_to_add.append(start_message)
    
    print(f"[æ‰§è¡Œ] æ­¥éª¤ {current_step + 1}/{len(plan)}: {step_description}")
    
    # å‡†å¤‡Agentç³»ç»Ÿæç¤º
    system_prompt = build_executor_prompt(state, current_step, step_description)
    
    # â­ å¦‚æœæœ‰ç”¨æˆ·è¾“å…¥ï¼Œæ³¨å…¥åˆ°promptä¸­
    if user_input:
        system_prompt += f"\n\nã€ç”¨æˆ·æä¾›çš„ä¿¡æ¯ã€‘\n{user_input}\nè¯·ä½¿ç”¨è¿™ä¸ªä¿¡æ¯å®Œæˆå½“å‰ä»»åŠ¡ã€‚"
    
    # åˆ›å»ºAgent
    agent = create_agent(
        system_prompt=system_prompt,
        model=mt_llm("gpt-4.1"),
        tools=[check_low_star_merchant, check_sensitive_merchant],
    )
    
    # æ‰§è¡Œ
    start_exec = time.time()
    execution_result = agent.invoke({"input": step_description})
    exec_duration = (time.time() - start_exec) * 1000
    
    output = execution_result["messages"][-1].content
    
    # â­ æ£€æŸ¥æ˜¯å¦éœ€è¦è¯¢é—®ç”¨æˆ·
    if "ask_human" in output.lower():
        print(f"[ä¸­æ–­] æ­¥éª¤ {current_step + 1} éœ€è¦ç”¨æˆ·è¾“å…¥")
        
        # æå–é—®é¢˜ï¼ˆAgentåº”è¯¥åœ¨è¾“å‡ºä¸­è¯´æ˜éœ€è¦ä»€ä¹ˆä¿¡æ¯ï¼‰
        question = output.replace("ask_human", "").strip()
        if not question:
            question = "è¯·æä¾›æ‰§è¡Œæ­¤æ­¥éª¤æ‰€éœ€çš„ä¿¡æ¯"
        
        # æ›´æ–°æ­¥éª¤çŠ¶æ€ä¸ºéœ€è¦æ¾„æ¸…
        step_result.status = StepStatus.NEED_CLARIFICATION
        step_result.interrupt_question = question
        step_result.end_time = datetime.now()
        step_result.duration_ms = exec_duration
        
        # æ·»åŠ ä¸­æ–­æ¶ˆæ¯
        interrupt_message = AIMessage(
            content=f"â¸ï¸ æ­¥éª¤ {current_step + 1} éœ€è¦æ›´å¤šä¿¡æ¯\n{question}"
        )
        messages_to_add.append(interrupt_message)
        
        # â­ ä¸­æ–­ï¼šä¸å¢åŠ current_stepï¼Œä¿æŒåœ¨å½“å‰æ­¥éª¤
        return Command(goto="ask_human", update={
            "response": question,
            "return_to": "plan_executor",
            "need_clarification": True,
            "step_results": [step_result],
            "messages": messages_to_add,
            # current_step ä¸å˜ï¼ç”¨æˆ·å›å¤åä¼šé‡æ–°æ‰§è¡Œè¿™ä¸€æ­¥
        })
    
    # æ­£å¸¸æ‰§è¡Œå®Œæˆ
    # æå–å·¥å…·è°ƒç”¨ä¿¡æ¯
    tool_calls = extract_tool_calls(execution_result)
    
    # æ›´æ–°ç»“æœ
    step_result.status = StepStatus.SUCCESS
    step_result.end_time = datetime.now()
    step_result.duration_ms = exec_duration
    step_result.agent_response = str(output)
    step_result.output_result = output[:500] if output else ""
    
    # â­ æ‰“å°æˆåŠŸæ—¥å¿—å’Œå·¥å…·ç»“æœ
    print(f"[æˆåŠŸ] æ­¥éª¤ {current_step + 1} å®Œæˆ,è€—æ—¶ {exec_duration:.2f}ms")
    
    # â­ å¦‚æœæœ‰å·¥å…·è°ƒç”¨ï¼Œæ‰“å°å·¥å…·ç»“æœ
    if tool_calls:
        print(f"[å·¥å…·è°ƒç”¨] æœ¬æ­¥éª¤è°ƒç”¨äº† {len(tool_calls)} ä¸ªå·¥å…·:")
        for tool_call in tool_calls:
            print(f"  â€¢ {tool_call.tool_name}")
            # æ‰“å°å…³é”®ç»“æœï¼ˆå¦‚æœæœ‰ï¼‰
            if tool_call.result:
                try:
                    import json
                    result_data = tool_call.result if isinstance(tool_call.result, dict) else {}
                    
                    # é’ˆå¯¹ä¸åŒå·¥å…·æ‰“å°å…³é”®ä¿¡æ¯
                    if 'check_sensitive_merchant' in tool_call.tool_name:
                        is_violated = result_data.get('is_violated', 'N/A')
                        risk_score = result_data.get('risk_score', 'N/A')
                        risk_score_v2 = result_data.get('risk_score_v2', 'N/A')
                        print(f"    â†’ is_violated={is_violated}, risk_score={risk_score}, risk_score_v2={risk_score_v2}")
                    
                    elif 'check_low_star_merchant' in tool_call.tool_name:
                        is_low_star = result_data.get('is_low_star', 'N/A')
                        shop_star = result_data.get('shop_star', 'N/A')
                        print(f"    â†’ is_low_star={is_low_star}, shop_star={shop_star}")
                    
                    elif 'get_trace_context' in tool_call.tool_name:
                        scene_code = result_data.get('scene_code', 'N/A')
                        exp_count = len(result_data.get('experiments', []))
                        print(f"    â†’ scene_code={scene_code}, å‘½ä¸­{exp_count}ä¸ªå®éªŒ")
                    
                    elif 'get_visit_record' in tool_call.tool_name:
                        count = result_data.get('count', 0)
                        print(f"    â†’ æ‰¾åˆ°{count}æ¡è®¿é—®è®°å½•")
                    
                    else:
                        # å…¶ä»–å·¥å…·ï¼Œæ‰“å°é€šç”¨ä¿¡æ¯
                        # å–å‰3ä¸ªé”®å€¼å¯¹
                        keys = list(result_data.keys())[:3]
                        summary = {k: result_data[k] for k in keys if k in result_data}
                        if summary:
                            print(f"    â†’ {summary}")
                
                except Exception as e:
                    # å¦‚æœè§£æå¤±è´¥ï¼Œè·³è¿‡
                    pass
    
    print()  # ç©ºè¡Œ
    
    # ğŸ“ æ·»åŠ æˆåŠŸæ¶ˆæ¯
    result_summary = step_result.output_result[:200] if step_result.output_result else "æ‰§è¡Œå®Œæˆ"
    tools_used = f" (ä½¿ç”¨äº†{len(tool_calls)}ä¸ªå·¥å…·)" if tool_calls else ""
    
    success_message = AIMessage(
        content=f"âœ… æ­¥éª¤ {current_step + 1} å®Œæˆ{tools_used}\n{result_summary}"
    )
    messages_to_add.append(success_message)
    
    # â­ æˆåŠŸåæ‰å¢åŠ current_step
    return {
        "current_step": current_step + 1,
        "step_results": [step_result],
        "messages": messages_to_add,
        "need_clarification": False,
        "past_steps": [(step_description, step_result.agent_response)]
    }


def build_executor_prompt(state: AgentState, step_index: int, task: str) -> str:
    """æ„å»ºæ‰§è¡Œå™¨æç¤ºè¯"""
    previous_results = state.get("step_results", [])
    context = ""
    if previous_results:
        context = "\n".join([
            f"æ­¥éª¤{i+1}: {r.step_description} -> {r.output_result or 'æ— ç»“æœ'}"
            for i, r in enumerate(previous_results[-3:])  # åªæ˜¾ç¤ºæœ€è¿‘3æ­¥
        ])

    return f"""ä½ æ˜¯ä¸€ä¸ªä¸¥æ ¼çš„è®¡åˆ’æ‰§è¡ŒèŠ‚ç‚¹ã€‚
ä½ çš„èŒè´£: ä»…æ‰§è¡Œå½“å‰æ­¥éª¤,ä¸è¿›è¡Œé¢å¤–æ¨ç†ã€‚

ç”¨æˆ·é—®é¢˜: {state['query']}
å½“å‰æ‰§è¡Œ: æ­¥éª¤ {step_index + 1} - {task}

å‰åºæ­¥éª¤ä¸Šä¸‹æ–‡:
{context or 'æ— '}

è¦æ±‚:
1. ä¸¥æ ¼æŒ‰ç…§å½“å‰æ­¥éª¤æè¿°æ‰§è¡Œ
2. å¦‚æœéœ€è¦è°ƒç”¨å·¥å…·,è¯·ç›´æ¥è°ƒç”¨
3. å¦‚æœä¿¡æ¯ä¸è¶³,è¾“å‡º "ask_human"ï¼Œè¯¢é—®äººç±»ã€‚å¹¶æ‹¼æ¥ä½ éœ€è¦è¯¢é—®çš„é—®é¢˜
4. ä¸è¦é‡å¤å‰é¢æ­¥éª¤çš„å·¥ä½œ
"""


def extract_tool_calls(result: dict) -> list:
    """ä»Agentç»“æœä¸­æå–å·¥å…·è°ƒç”¨ä¿¡æ¯"""
    tool_calls_list = []
    messages = result.get("messages", [])

    for msg in messages:
        if hasattr(msg, "tool_calls") and msg.tool_calls:
            for tc in msg.tool_calls:
                tool_calls_list.append(ToolCall(
                    tool_name=tc.get("name", "unknown"),
                    arguments=tc.get("args", {}),
                    result=tc.get("result"),
                    error=tc.get("error")
                ))

    return tool_calls_list


def extract_output(result: dict) -> str:
    """æå–è¾“å‡ºç»“æœ"""
    if "output" in result:
        return str(result["output"])
    if "messages" in result and result["messages"]:
        last_msg = result["messages"][-1]
        if hasattr(last_msg, "content"):
            return last_msg.content
    return ""


def finalize_execution(state: AgentState) -> dict:
    """å®Œæˆæ‰§è¡Œ,ç”Ÿæˆæ‘˜è¦"""
    from langchain_core.messages import AIMessage
    
    step_results = state.get("step_results", [])

    summary = PlanExecutionSummary(
        # plan_id=state.get("thread_id", "unknown"),
        query=state.get("query", ""),
        intent=state.get("intent"),
        is_sop=state.get("is_sop_matched", False),
        total_steps=len(state.get("plan", [])),
        plan_steps=state.get("plan", []),
        completed_steps=len([r for r in step_results if r.status == StepStatus.SUCCESS]),
        failed_steps=len([r for r in step_results if r.status == StepStatus.FAILED]),
        skipped_steps=len([r for r in step_results if r.status == StepStatus.SKIPPED]),
        overall_status=StepStatus.SUCCESS if all(
            r.status == StepStatus.SUCCESS for r in step_results
        ) else StepStatus.FAILED,
        final_response=state.get("response", "")
    )

    if step_results:
        summary.start_time = step_results[0].start_time
        summary.end_time = step_results[-1].end_time
        if summary.start_time and summary.end_time:
            summary.total_duration_ms = (
                summary.end_time - summary.start_time
            ).total_seconds() * 1000
    
    # ğŸ“ æ·»åŠ å®Œæˆæ¶ˆæ¯
    status_emoji = "ğŸ‰" if summary.overall_status == StepStatus.SUCCESS else "âš ï¸"
    completion_message = AIMessage(
        content=f"{status_emoji} æ‰€æœ‰æ­¥éª¤å·²å®Œæˆ\n" +
                f"â€¢ æ€»è®¡: {summary.total_steps} æ­¥\n" +
                f"â€¢ æˆåŠŸ: {summary.completed_steps} æ­¥\n" +
                f"â€¢ å¤±è´¥: {summary.failed_steps} æ­¥\n" +
                f"â€¢ æ€»è€—æ—¶: {summary.total_duration_ms:.0f}ms"
    )

    return {
        "execution_summary": summary,
        "messages": [completion_message]
    }


def replan_node(state: AgentState) -> dict:
    """
    é‡æ–°è§„åˆ’èŠ‚ç‚¹ - è¯„ä¼°æ‰§è¡Œç»“æœå¹¶å†³å®šä¸‹ä¸€æ­¥è¡ŒåŠ¨
    
    èŒè´£ï¼š
    1. è¯„ä¼°å·²æ‰§è¡Œæ­¥éª¤çš„ç»“æœ
    2. åˆ¤æ–­æ˜¯å¦å·²æ”¶é›†è¶³å¤Ÿä¿¡æ¯å¯ä»¥å›ç­”ç”¨æˆ·
    3. åˆ¤æ–­æ˜¯å¦éœ€è¦è°ƒæ•´è®¡åˆ’æˆ–é‡æ–°è§„åˆ’
    4. å†³å®šï¼šç»§ç»­æ‰§è¡Œ / é‡æ–°è§„åˆ’ / ç»“æŸå¹¶å“åº”
    
    â­ SOPæ¨¡å¼ï¼šåªæœ‰æ‰§è¡Œå®Œæ‰€æœ‰SOPæ­¥éª¤åæ‰å…è®¸replan
    """
    from langchain_core.messages import AIMessage, SystemMessage
    from langchain_core.output_parsers import JsonOutputParser
    from langchain_core.prompts import ChatPromptTemplate
    
    query = state.get("query", "")
    plan = state.get("plan", [])
    current_step = state.get("current_step", 0)
    step_results = state.get("step_results", [])
    is_sop_matched = state.get("is_sop_matched", False)
    
    # â­ æ£€æŸ¥æ˜¯å¦æ‰€æœ‰SOPæ­¥éª¤å·²æ‰§è¡Œå®Œæ¯•
    # é€šè¿‡æ¯”è¾ƒstep_resultsæ•°é‡å’ŒåŸå§‹plané•¿åº¦åˆ¤æ–­
    # å¦‚æœstep_resultsä¸­çš„æ­¥éª¤éƒ½æ¥è‡ªåŸå§‹planï¼Œè¯´æ˜è¿˜åœ¨SOPé˜¶æ®µ
    sop_completed = False
    if is_sop_matched and step_results:
        # æ£€æŸ¥æ˜¯å¦æœ‰step_index >= len(plan)çš„ç»“æœï¼ˆè¯´æ˜å·²ç»replanè¿‡ï¼‰
        max_step_index = max([r.step_index for r in step_results])
        # æˆ–è€…æ£€æŸ¥current_stepæ˜¯å¦å·²ç»åˆ°è¾¾æˆ–è¶…è¿‡åŸå§‹plané•¿åº¦
        if current_step >= len(plan):
            sop_completed = True
            print(f"[Replan] SOPå·²å…¨éƒ¨æ‰§è¡Œå®Œæ¯• ({len(plan)}æ­¥ï¼‰ï¼Œç°åœ¨å…è®¸replan")
    
    # å¦‚æœè¿˜æ²¡æœ‰æ‰§è¡Œä»»ä½•æ­¥éª¤ï¼Œç›´æ¥ç»§ç»­
    if not step_results:
        return {}
    
    # æ„å»ºå·²å®Œæˆæ­¥éª¤çš„æ‘˜è¦
    completed_steps_summary = []
    for result in step_results:
        status = "âœ… æˆåŠŸ" if result.status == "success" else "âŒ å¤±è´¥"
        summary = f"{status} æ­¥éª¤{result.step_index + 1}: {result.step_description}"
        if result.output_result:
            summary += f"\n   ç»“æœ: {result.output_result[:150]}"
        if result.error_message:
            summary += f"\n   é”™è¯¯: {result.error_message[:100]}"
        completed_steps_summary.append(summary)
    
    # å‰©ä½™æ­¥éª¤
    remaining_steps = plan[current_step:] if current_step < len(plan) else []
    
    # â­ æ ¹æ®SOPçŠ¶æ€æ„å»ºä¸åŒçš„æç¤º
    if is_sop_matched and not sop_completed:
        # SOPæ‰§è¡Œä¸­ï¼šä¸å…è®¸replan
        replan_prompt = f"""ä½ æ˜¯ä¸€ä¸ªSOP(æ ‡å‡†æ“ä½œæµç¨‹)æ‰§è¡Œè¯„ä¼°åŠ©æ‰‹ã€‚å½“å‰æ­£åœ¨æ‰§è¡ŒSOPæµç¨‹ã€‚

ç”¨æˆ·é—®é¢˜ï¼š{query}

SOPå›ºå®šæµç¨‹ï¼š
{chr(10).join([f"{i+1}. {step}" for i, step in enumerate(plan)])}

å·²å®Œæˆçš„æ­¥éª¤ï¼š
{chr(10).join(completed_steps_summary)}

å‰©ä½™SOPæ­¥éª¤ï¼š
{chr(10).join([f"{i+current_step+1}. {step}" for i, step in enumerate(remaining_steps)]) if remaining_steps else "æ— "}

âš ï¸ é‡è¦ï¼šå½“å‰åœ¨æ‰§è¡ŒSOPæµç¨‹ï¼Œè¿˜æœ‰{len(remaining_steps)}ä¸ªæ­¥éª¤æœªå®Œæˆã€‚

è¯·è¯„ä¼°ï¼š
1. å·²å®Œæˆçš„æ­¥éª¤æ˜¯å¦æ”¶é›†äº†è¶³å¤Ÿä¿¡æ¯æ¥å›ç­”ç”¨æˆ·ï¼ˆå¯æå‰ç»“æŸSOPï¼‰ï¼Ÿ
2. å¦‚æœä¿¡æ¯è¶³å¤Ÿï¼Œè¯·ç”Ÿæˆæœ€ç»ˆå“åº”
3. å¦‚æœä¿¡æ¯ä¸è¶³ï¼Œå¿…é¡»ç»§ç»­æ‰§è¡Œå‰©ä½™SOPæ­¥éª¤

è¾“å‡ºæ ¼å¼ï¼š
{{
    "decision": "respond" æˆ– "continue",
    "reasoning": "ä½ çš„æ¨ç†è¿‡ç¨‹",
    "response": "æœ€ç»ˆå“åº”ï¼ˆä»…å½“decisionä¸ºrespondæ—¶ï¼‰"
}}

å†³ç­–è¯´æ˜ï¼š
- respond: å·²æœ‰è¶³å¤Ÿä¿¡æ¯ï¼Œå¯ä»¥å›ç­”ç”¨æˆ·
- continue: ç»§ç»­æ‰§è¡Œå‰©ä½™SOPæ­¥éª¤
- âŒ ç¦æ­¢replanï¼ˆå¿…é¡»å…ˆå®Œæˆæ‰€æœ‰SOPæ­¥éª¤ï¼‰
"""
    else:
        # éSOPæ¨¡å¼ æˆ– SOPå·²å®Œæˆï¼šå…è®¸replan
        sop_completed_note = "ï¼ˆSOPå·²å…¨éƒ¨æ‰§è¡Œå®Œæ¯•ï¼Œå¯ä»¥é‡æ–°è§„åˆ’ï¼‰" if is_sop_matched else ""
        replan_prompt = f"""ä½ æ˜¯ä¸€ä¸ªæ™ºèƒ½è§„åˆ’è¯„ä¼°åŠ©æ‰‹ã€‚ä½ çš„ä»»åŠ¡æ˜¯è¯„ä¼°å½“å‰æ‰§è¡Œæƒ…å†µï¼Œå¹¶å†³å®šä¸‹ä¸€æ­¥è¡ŒåŠ¨ã€‚{sop_completed_note}

ç”¨æˆ·é—®é¢˜ï¼š{query}

å½“å‰è®¡åˆ’ï¼š
{chr(10).join([f"{i+1}. {step}" for i, step in enumerate(plan)])}

å·²å®Œæˆçš„æ­¥éª¤ï¼š
{chr(10).join(completed_steps_summary)}

å‰©ä½™æ­¥éª¤ï¼š
{chr(10).join([f"{i+current_step+1}. {step}" for i, step in enumerate(remaining_steps)]) if remaining_steps else "æ— "}

è¯·è¯„ä¼°ï¼š
1. å·²å®Œæˆçš„æ­¥éª¤æ˜¯å¦æ”¶é›†äº†è¶³å¤Ÿçš„ä¿¡æ¯æ¥å›ç­”ç”¨æˆ·é—®é¢˜ï¼Ÿ
2. å¦‚æœä¿¡æ¯è¶³å¤Ÿï¼Œè¯·ç”Ÿæˆæœ€ç»ˆå“åº”
3. å¦‚æœä¿¡æ¯ä¸è¶³ï¼š
   - å‰©ä½™æ­¥éª¤æ˜¯å¦åˆç†ï¼Ÿå¦‚æœåˆç†ï¼Œç»§ç»­æ‰§è¡Œ
   - å‰©ä½™æ­¥éª¤ä¸åˆç†æˆ–éœ€è¦è°ƒæ•´ï¼Ÿç”Ÿæˆæ–°çš„è®¡åˆ’

è¾“å‡ºæ ¼å¼ï¼š
{{
    "decision": "respond" æˆ– "continue" æˆ– "replan",
    "reasoning": "ä½ çš„æ¨ç†è¿‡ç¨‹",
    "response": "æœ€ç»ˆå“åº”ï¼ˆä»…å½“decisionä¸ºrespondæ—¶ï¼‰",
    "new_plan": ["æ–°æ­¥éª¤1", "æ–°æ­¥éª¤2"] ï¼ˆä»…å½“decisionä¸ºreplanæ—¶ï¼‰
}}

å†³ç­–è¯´æ˜ï¼š
- respond: å·²æœ‰è¶³å¤Ÿä¿¡æ¯ï¼Œå¯ä»¥å›ç­”ç”¨æˆ·
- continue: ç»§ç»­æ‰§è¡Œå‰©ä½™è®¡åˆ’
- replan: éœ€è¦è°ƒæ•´è®¡åˆ’æˆ–é‡æ–°è§„åˆ’
"""

    # è°ƒç”¨LLMè¿›è¡Œå†³ç­–
    messages = [
        SystemMessage(content="ä½ æ˜¯ä¸€ä¸ªæ™ºèƒ½è§„åˆ’è¯„ä¼°åŠ©æ‰‹ï¼Œæ“…é•¿åˆ†ææ‰§è¡Œç»“æœå¹¶åšå‡ºåˆç†å†³ç­–ã€‚"),
        {"role": "user", "content": replan_prompt}
    ]
    
    try:
        result = q_max.invoke(messages)
        
        # è§£æLLMå“åº”
        import json
        try:
            decision_data = json.loads(result.content)
        except:
            # å¦‚æœJSONè§£æå¤±è´¥ï¼Œä½¿ç”¨JsonOutputParser
            from langchain_core.output_parsers import StrOutputParser
            parser = StrOutputParser()
            content = parser.invoke(result)
            # å°è¯•ä»contentä¸­æå–JSON
            import re
            json_match = re.search(r'\{.*\}', content, re.DOTALL)
            if json_match:
                decision_data = json.loads(json_match.group())
            else:
                # é»˜è®¤ç»§ç»­æ‰§è¡Œ
                decision_data = {
                    "decision": "continue",
                    "reasoning": "æ— æ³•è§£æLLMå“åº”ï¼Œé»˜è®¤ç»§ç»­æ‰§è¡Œ"
                }
        
        decision = decision_data.get("decision", "continue")
        reasoning = decision_data.get("reasoning", "")
        
        print(f"\n[Replan] å†³ç­–: {decision}")
        print(f"[Replan] æ¨ç†: {reasoning}")
        
        messages_to_add = []
        
        # æ ¹æ®å†³ç­–è¿”å›ä¸åŒçš„ç»“æœ
        if decision == "respond":
            # å·²æœ‰è¶³å¤Ÿä¿¡æ¯ï¼Œç”Ÿæˆæœ€ç»ˆå“åº”
            response_text = decision_data.get("response", "")
            
            response_message = AIMessage(
                content=f"ğŸ’¡ å·²æ”¶é›†è¶³å¤Ÿä¿¡æ¯ï¼Œç”Ÿæˆæœ€ç»ˆç­”æ¡ˆ\n{response_text}"
            )
            messages_to_add.append(response_message)
            
            return {
                "response": response_text,
                "messages": messages_to_add,
                # æ ‡è®°ä¸ºå®Œæˆï¼Œåœæ­¢ç»§ç»­æ‰§è¡Œ
                "current_step": len(plan)  # è®¾ç½®ä¸ºè®¡åˆ’é•¿åº¦ï¼Œè§¦å‘å®Œæˆ
            }
        
        elif decision == "replan":
            # éœ€è¦é‡æ–°è§„åˆ’
            new_plan = decision_data.get("new_plan", [])
            
            replan_message = AIMessage(
                content=f"ğŸ”„ éœ€è¦è°ƒæ•´è®¡åˆ’\nåŸå› : {reasoning}\næ–°è®¡åˆ’:\n" +
                        "\n".join([f"{i+1}. {step}" for i, step in enumerate(new_plan)])
            )
            messages_to_add.append(replan_message)
            
            return {
                "plan": new_plan,
                "current_step": 0,  # é‡ç½®åˆ°ç¬¬ä¸€æ­¥
                "messages": messages_to_add
            }
        
        else:  # continue
            # ç»§ç»­æ‰§è¡Œå‰©ä½™è®¡åˆ’
            continue_message = AIMessage(
                content=f"â–¶ï¸ ç»§ç»­æ‰§è¡Œå‰©ä½™è®¡åˆ’\nåŸå› : {reasoning}"
            )
            messages_to_add.append(continue_message)
            
            return {
                "messages": messages_to_add
            }
    
    except Exception as e:
        print(f"[Replan] é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
        
        # å‡ºé”™æ—¶é»˜è®¤ç»§ç»­æ‰§è¡Œ
        error_message = AIMessage(
            content=f"âš ï¸ è¯„ä¼°è¿‡ç¨‹å‡ºé”™ï¼Œç»§ç»­æ‰§è¡ŒåŸè®¡åˆ’\né”™è¯¯: {str(e)[:100]}"
        )
        
        return {
            "messages": [error_message]
        }
