from langgraph.types import Command, interrupt

from langchain.agents import create_agent

from langchain_core.output_parsers import JsonOutputParser
from langchain_core.prompts import PromptTemplate
from datetime import datetime
import time

from src.config.llm import q_max, get_gpt_model, mt_llm, q_plus
from src.graph_state import AgentState, Plan
from src.prompt.plan import planner_prompt_template
from src.tools import (
    ALL_TOOLS,
    check_low_star_merchant, 
    check_sensitive_merchant,
    search_user_access_history,
    restore_user_scene,
    analyze_recall_chain,
    parse_user_query_params
)
from src.models.execution_result import (
    StepExecutionResult,
    StepStatus,
    ToolCall,
    PlanExecutionSummary,
    TokenUsage
)


async def planning_node(state: AgentState):
    """ç”Ÿæˆæ‰§è¡Œè®¡åˆ’ - æ ¹æ®intentåŠ¨æ€é€‰æ‹©prompt"""
    from langchain_core.messages import AIMessage
    from src.config.sop_loader import get_sop_loader
    
    faq_query = state['faq_query']
    intent = state.get('intent', 'default')
    
    # â­ ä»SOPLoaderè·å–planning prompt
    sop_loader = get_sop_loader()
    prompt_template_text = sop_loader.get_planning_prompt(intent)
    
    # å¦‚æœæ²¡æœ‰ä¸“ä¸špromptï¼Œé™çº§åˆ°é€šç”¨prompt
    if not prompt_template_text:
        prompt_template_text = planner_prompt_template
        print(f"[Planning] Using default prompt (no custom for '{intent}')")
    else:
        print(f"[Planning] Using custom prompt for '{intent}'")
    
    # å‡†å¤‡parserå’Œæ ¼å¼åŒ–
    plan_parser = JsonOutputParser(pydantic_object=Plan)
    format_instructions = plan_parser.get_format_instructions()
    
    final_prompt = prompt_template_text.format(
        query=faq_query,
        format_instructions=format_instructions
    )
    
    # è°ƒç”¨LLMï¼ˆå¼‚æ­¥ï¼‰
    planner_prompt = PromptTemplate(
        template="{text}",
        input_variables=["text"]
    )
    chain = planner_prompt | q_max | JsonOutputParser()
    result = await chain.ainvoke({"text": final_prompt})
    
    steps = result.get('steps', [])
    
    # ğŸ“ æ·»åŠ è®¡åˆ’ç”Ÿæˆæ¶ˆæ¯
    plan_message = AIMessage(
        content=f"ğŸ“‹ [{intent}] å·²ç”Ÿæˆæ‰§è¡Œè®¡åˆ’ï¼Œå…±{len(steps)}ä¸ªæ­¥éª¤:\n" + 
                "\n".join([f"{i+1}. {step}" for i, step in enumerate(steps)])
    )
    
    return {
        "plan": steps,
        "current_step": 0,
        "messages": [plan_message]
    }


async def plan_executor_node(state: AgentState):
    """å¢å¼ºç‰ˆè®¡åˆ’æ‰§è¡ŒèŠ‚ç‚¹ - æ”¯æŒHuman-in-the-Loopï¼ˆå¼‚æ­¥ç‰ˆæœ¬ï¼‰"""
    plan = state.get("plan", [])
    current_step = state.get("current_step", 0)
    
    # æ£€æŸ¥æ˜¯å¦å·²å®Œæˆæ‰€æœ‰æ­¥éª¤
    if current_step >= len(plan):
        print(f"[PlanExecutor] æ‰€æœ‰æ­¥éª¤å·²å®Œæˆ")
        return finalize_execution(state)
    
    step_description = plan[current_step]
    
    # åˆå§‹åŒ–æ­¥éª¤æ‰§è¡Œç»“æœ
    step_result = StepExecutionResult(
        step_index=current_step,
        step_description=step_description,
        status=StepStatus.RUNNING,
        start_time=datetime.now(),
        input_context={
            "query": state.get("query"),
            "previous_steps": len(state.get("step_results", [])),
            "faq_context": state.get("faq_response")
        }
    )
    
    # ğŸ“ æ·»åŠ æ¶ˆæ¯
    from langchain_core.messages import AIMessage
    from langchain_core.messages import HumanMessage # Added for new logic
    messages_to_add = []
    
    # â­ æ£€æŸ¥æ˜¯å¦æœ‰ç”¨æˆ·åˆšåˆšçš„å›å¤ï¼ˆç”¨äºæ¢å¤ï¼‰
    user_input = None
    messages = state.get("messages", [])
    
    # æ”¹è¿›é€»è¾‘ï¼šå€’åºæŸ¥æ‰¾æœ€è¿‘çš„ä¸€æ¬¡ [AIMessage(â¸ï¸) -> ... -> HumanMessage] æ¨¡å¼
    # å…è®¸ä¸­é—´ç”± ReplanNode æ’å…¥çš„å…¶ä»– AIMessage
    
    last_ask_index = -1
    for i in range(len(messages) - 1, -1, -1):
        msg = messages[i]
        if isinstance(msg, AIMessage) and "â¸ï¸" in str(msg.content):
            last_ask_index = i
            break
            
    if last_ask_index != -1:
        # æ‰¾åˆ°äº†æœ€è¿‘çš„æé—®ï¼Œæ£€æŸ¥å…¶åæ˜¯å¦æœ‰ HumanMessage
        # é€šå¸¸ HumanMessage åº”è¯¥åœ¨ Ask ä¹‹å
        for i in range(last_ask_index + 1, len(messages)):
            if isinstance(messages[i], HumanMessage):
                user_input = messages[i].content
                # æ‰¾åˆ°ç¬¬ä¸€ä¸ª HumanMessage å³åœæ­¢ï¼Œè§†ä¸ºå›å¤
                break

    if user_input:
        print(f"[Executor] æ£€æµ‹åˆ°ç”¨æˆ·å›å¤: {user_input}")
        
        # æ·»åŠ æ¢å¤æ¶ˆæ¯
        resume_message = AIMessage(
            content=f"â–¶ï¸ æ”¶åˆ°æ‚¨çš„å›å¤ï¼Œç»§ç»­æ‰§è¡Œæ­¥éª¤ {current_step + 1}"
        )
        messages_to_add.append(resume_message)
    
    if not user_input:
        # é¦–æ¬¡æ‰§è¡Œæ­¤æ­¥éª¤ï¼Œæ·»åŠ å¼€å§‹æ¶ˆæ¯
        start_message = AIMessage(
            content=f"ğŸ”„ å¼€å§‹æ‰§è¡Œæ­¥éª¤ {current_step + 1}/{len(plan)}: {step_description}"
        )
        messages_to_add.append(start_message)
    
    print(f"[æ‰§è¡Œ] æ­¥éª¤ {current_step + 1}/{len(plan)}: {step_description}")
    
    # å‡†å¤‡Agentç³»ç»Ÿæç¤º
    system_prompt = build_executor_prompt(state, current_step, step_description)
    
    # â­ è·å– MCP å·¥å…·å¹¶åˆå¹¶
    from src.mcp import get_mcp_manager
    
    mcp_manager = get_mcp_manager()
    mcp_tools = mcp_manager.get_all_tools()
    
    # åˆå¹¶é™æ€å·¥å…·å’Œ MCP å·¥å…·
    all_tools = ALL_TOOLS + mcp_tools
    
    if mcp_tools:
        print(f"[MCP] å·²åŠ è½½ {len(mcp_tools)} ä¸ª MCP å·¥å…·")
    
    # åˆ›å»ºAgent
    agent = create_agent(
        system_prompt=system_prompt,
        # model=mt_llm("gpt-4.1"),
        model=q_plus,
        tools=all_tools,  # â­ ä½¿ç”¨åˆå¹¶åçš„å·¥å…·åˆ—è¡¨
    )
    
    # æ‰§è¡Œï¼ˆå¼‚æ­¥ï¼‰
    start_exec = time.time()
    # â­ ä½¿ç”¨ ainvoke è€Œä¸æ˜¯ invokeï¼Œæ”¯æŒå¼‚æ­¥å·¥å…·è°ƒç”¨
    execution_result = await agent.ainvoke({
        "input": step_description,
        # "chat_history": state.get("messages", [])
    })
    exec_duration = (time.time() - start_exec) * 1000
    
    # â­ æå– Token Usage
    token_usage = TokenUsage()
    if "messages" in execution_result and execution_result["messages"]:
        last_msg = execution_result["messages"][-1]
        if hasattr(last_msg, "response_metadata"):
            usage_data = last_msg.response_metadata.get("token_usage", {})
            if usage_data:
                token_usage = TokenUsage(
                    prompt_tokens=usage_data.get("prompt_tokens", 0),
                    completion_tokens=usage_data.get("completion_tokens", 0),
                    total_tokens=usage_data.get("total_tokens", 0)
                )
                print(f"[èµ„æº] Tokenæ¶ˆè€—: {token_usage.total_tokens} (Prompt: {token_usage.prompt_tokens}, Completion: {token_usage.completion_tokens})")
    
    output = execution_result["messages"][-1].content
    
    # â­ æ£€æŸ¥æ˜¯å¦éœ€è¦è¯¢é—®ç”¨æˆ·
    if "ask_human" in output.lower():
        print(f"[ä¸­æ–­] æ­¥éª¤ {current_step + 1} éœ€è¦ç”¨æˆ·è¾“å…¥")
        
        # æå–é—®é¢˜ï¼ˆAgentåº”è¯¥åœ¨è¾“å‡ºä¸­è¯´æ˜éœ€è¦ä»€ä¹ˆä¿¡æ¯ï¼‰
        question = output.replace("ask_human", "").strip()
        if not question:
            question = "è¯·æä¾›æ‰§è¡Œæ­¤æ­¥éª¤æ‰€éœ€çš„ä¿¡æ¯"
        
        # æ›´æ–°æ­¥éª¤çŠ¶æ€ä¸ºéœ€è¦æ¾„æ¸…
        step_result.status = StepStatus.NEED_CLARIFICATION
        step_result.interrupt_question = question
        step_result.end_time = datetime.now()
        step_result.duration_ms = exec_duration
        
        # æ·»åŠ ä¸­æ–­æ¶ˆæ¯
        interrupt_message = AIMessage(
            content=f"â¸ï¸ æ­¥éª¤ {current_step + 1} éœ€è¦æ›´å¤šä¿¡æ¯\n{question}"
        )
        messages_to_add.append(interrupt_message)
        
        # â­ ä¸­æ–­ï¼šä¸å¢åŠ current_stepï¼Œä¿æŒåœ¨å½“å‰æ­¥éª¤
        return Command(goto="ask_human", update={
            "response": question,
            "return_to": "plan_executor",
            "need_clarification": True,
            "step_results": [step_result],
            "messages": messages_to_add,
            # current_step ä¸å˜ï¼ç”¨æˆ·å›å¤åä¼šé‡æ–°æ‰§è¡Œè¿™ä¸€æ­¥
        })
    
    # æ­£å¸¸æ‰§è¡Œå®Œæˆ
    # æå–å·¥å…·è°ƒç”¨ä¿¡æ¯
    tool_calls = extract_tool_calls(execution_result)
    
    # æ›´æ–°ç»“æœ
    step_result.status = StepStatus.SUCCESS
    step_result.end_time = datetime.now()
    step_result.duration_ms = exec_duration
    step_result.token_usage = token_usage
    step_result.agent_response = str(output)
    step_result.output_result = output[:500] if output else ""
    
    # â­ æ‰“å°æˆåŠŸæ—¥å¿—å’Œå·¥å…·ç»“æœ
    print(f"[æˆåŠŸ] æ­¥éª¤ {current_step + 1} å®Œæˆ,è€—æ—¶ {exec_duration:.2f}ms")
    
    # â­ å¦‚æœæœ‰å·¥å…·è°ƒç”¨ï¼Œæ‰“å°å·¥å…·ç»“æœ
    if tool_calls:
        print(f"[å·¥å…·è°ƒç”¨] æœ¬æ­¥éª¤è°ƒç”¨äº† {len(tool_calls)} ä¸ªå·¥å…·:")
        for tool_call in tool_calls:
            print(f"  â€¢ {tool_call.tool_name}")
            # æ‰“å°å…³é”®ç»“æœï¼ˆå¦‚æœæœ‰ï¼‰
            if tool_call.result:
                try:
                    import json
                    result_data = tool_call.result if isinstance(tool_call.result, dict) else {}
                    
                    # é’ˆå¯¹ä¸åŒå·¥å…·æ‰“å°å…³é”®ä¿¡æ¯
                    if 'check_sensitive_merchant' in tool_call.tool_name:
                        is_violated = result_data.get('is_violated', 'N/A')
                        risk_score = result_data.get('risk_score', 'N/A')
                        risk_score_v2 = result_data.get('risk_score_v2', 'N/A')
                        print(f"    â†’ is_violated={is_violated}, risk_score={risk_score}, risk_score_v2={risk_score_v2}")
                    
                    elif 'check_low_star_merchant' in tool_call.tool_name:
                        is_low_star = result_data.get('is_low_star', 'N/A')
                        shop_star = result_data.get('shop_star', 'N/A')
                        print(f"    â†’ is_low_star={is_low_star}, shop_star={shop_star}")
                    
                    # â­ ç”¨æˆ·æ—¥å¿—å·¥å…·ç»“æœæ‰“å°
                    elif 'search_user_access_history' in tool_call.tool_name:
                        record_count = result_data.get('count', 0)
                        print(f"    â†’ æ‰¾åˆ°{record_count}æ¡è®¿é—®è®°å½•")

                    elif 'restore_user_scene' in tool_call.tool_name:
                        if 'error' in result_data:
                            print(f"    â†’ è¿˜åŸå¤±è´¥: {result_data['error']}")
                        else:
                            merchant_count = len(result_data.get('merchants', []))
                            click_count = len(result_data.get('click_records', []))
                            print(f"    â†’ å±•ç¤º{merchant_count}ä¸ªå•†æˆ·, {click_count}æ¬¡ç‚¹å‡», é¡µé¢: {result_data.get('display_info', {}).get('page')}")

                    elif 'analyze_recall_chain' in tool_call.tool_name:
                        issue = result_data.get('root_cause', 'N/A')
                        print(f"    â†’ æ ¹å› ={issue}")
                    
                    elif 'parse_user_query_params' in tool_call.tool_name:
                        print(f"    â†’ æå–å‚æ•°: {result_data}")
                    
                    elif 'get_trace_context' in tool_call.tool_name:
                        scene_code = result_data.get('scene_code', 'N/A')
                        exp_count = len(result_data.get('experiments', []))
                        print(f"    â†’ scene_code={scene_code}, å‘½ä¸­{exp_count}ä¸ªå®éªŒ")
                    
                    elif 'get_visit_record' in tool_call.tool_name:
                        count = result_data.get('count', 0)
                        print(f"    â†’ æ‰¾åˆ°{count}æ¡è®¿é—®è®°å½•")
                    
                    else:
                        # å…¶ä»–å·¥å…·ï¼Œæ‰“å°é€šç”¨ä¿¡æ¯
                        # å–å‰3ä¸ªé”®å€¼å¯¹
                        keys = list(result_data.keys())[:3]
                        summary = {k: result_data[k] for k in keys if k in result_data}
                        if summary:
                            print(f"    â†’ {summary}")
                
                except Exception as e:
                    # å¦‚æœè§£æå¤±è´¥ï¼Œè·³è¿‡
                    pass
    
    print()  # ç©ºè¡Œ
    
    # ğŸ“ æ·»åŠ æˆåŠŸæ¶ˆæ¯
    result_summary = step_result.output_result[:200] if step_result.output_result else "æ‰§è¡Œå®Œæˆ"
    tools_used = f" (ä½¿ç”¨äº†{len(tool_calls)}ä¸ªå·¥å…·)" if tool_calls else ""
    
    success_message = AIMessage(
        content=f"âœ… æ­¥éª¤ {current_step + 1} å®Œæˆ{tools_used}\n{result_summary}"
    )
    messages_to_add.append(success_message)
    
    # â­ æˆåŠŸåæ‰å¢åŠ current_step
    return {
        "current_step": current_step + 1,
        "step_results": [step_result],
        "messages": messages_to_add,
        "need_clarification": False,
        "past_steps": [(step_description, step_result.agent_response)]
    }


def build_executor_prompt(state: AgentState, step_index: int, task: str) -> str:
    """æ„å»ºæ‰§è¡Œå™¨æç¤ºè¯"""
    previous_results = state.get("step_results", [])
    context = ""
    if previous_results:
        context = "\n".join([
            f"æ­¥éª¤{i+1}: {r.step_description} -> {r.output_result or 'æ— ç»“æœ'}"
            for i, r in enumerate(previous_results[-3:])  # åªæ˜¾ç¤ºæœ€è¿‘3æ­¥
        ])

    # â­ å°†å¯¹è¯å†å²ä¹Ÿæ”¾å…¥System Promptä¸­
    chat_history_str = ""
    messages = state.get("messages", [])
    if messages:
        chat_history_str = "\n".join([
            f"{msg.type}: {msg.content}" 
            for msg in messages 
            if msg.type in ['human', 'ai']
        ])

    return f"""ä½ æ˜¯ä¸€ä¸ªä¸¥æ ¼çš„è®¡åˆ’æ‰§è¡ŒèŠ‚ç‚¹ã€‚
ä½ çš„èŒè´£: ä»…æ‰§è¡Œå½“å‰æ­¥éª¤,ä¸è¿›è¡Œé¢å¤–æ¨ç†ã€‚

ç”¨æˆ·é—®é¢˜: {state['query']}
å½“å‰æ‰§è¡Œ: æ­¥éª¤ {step_index + 1} - {task}

å‰åºæ­¥éª¤ä¸Šä¸‹æ–‡:
{context or 'æ— '}

å¯¹è¯å†å²:
{chat_history_str or 'æ— '}

è¦æ±‚:
1. ä¸¥æ ¼æŒ‰ç…§å½“å‰æ­¥éª¤æè¿°æ‰§è¡Œ
2. å¦‚æœéœ€è¦è°ƒç”¨å·¥å…·,è¯·ç›´æ¥è°ƒç”¨
3. å¦‚æœä¿¡æ¯ä¸è¶³,è¾“å‡º "ask_human"ï¼Œè¯¢é—®äººç±»ã€‚å¹¶æ‹¼æ¥ä½ éœ€è¦è¯¢é—®çš„é—®é¢˜
4. ä¸è¦é‡å¤å‰é¢æ­¥éª¤çš„å·¥ä½œ
"""


def extract_tool_calls(result: dict) -> list:
    """ä»Agentç»“æœä¸­æå–å·¥å…·è°ƒç”¨ä¿¡æ¯"""
    tool_calls_list = []
    messages = result.get("messages", [])

    for msg in messages:
        if hasattr(msg, "tool_calls") and msg.tool_calls:
            for tc in msg.tool_calls:
                tool_calls_list.append(ToolCall(
                    tool_name=tc.get("name", "unknown"),
                    arguments=tc.get("args", {}),
                    result=tc.get("result"),
                    error=tc.get("error")
                ))

    return tool_calls_list


def extract_output(result: dict) -> str:
    """æå–è¾“å‡ºç»“æœ"""
    if "output" in result:
        return str(result["output"])
    if "messages" in result and result["messages"]:
        last_msg = result["messages"][-1]
        if hasattr(last_msg, "content"):
            return last_msg.content
    return ""


def finalize_execution(state: AgentState) -> dict:
    """å®Œæˆæ‰§è¡Œ,ç”Ÿæˆæ‘˜è¦"""
    from langchain_core.messages import AIMessage
    
    step_results = state.get("step_results", [])

    summary = PlanExecutionSummary(
        # plan_id=state.get("thread_id", "unknown"),
        query=state.get("query", ""),
        intent=state.get("intent"),
        is_sop=state.get("is_sop_matched", False),
        total_steps=len(state.get("plan", [])),
        plan_steps=state.get("plan", []),
        completed_steps=len([r for r in step_results if r.status == StepStatus.SUCCESS]),
        failed_steps=len([r for r in step_results if r.status == StepStatus.FAILED]),
        skipped_steps=len([r for r in step_results if r.status == StepStatus.SKIPPED]),
        overall_status=StepStatus.SUCCESS if all(
            r.status == StepStatus.SUCCESS for r in step_results
        ) else StepStatus.FAILED,
        final_response=state.get("response", "")
    )

    # â­ èšåˆ Token Usage
    total_tokens = TokenUsage()
    for res in step_results:
        if res.token_usage:
            total_tokens.add(res.token_usage)
    summary.total_token_usage = total_tokens

    if step_results:
        summary.start_time = step_results[0].start_time
        summary.end_time = step_results[-1].end_time
        if summary.start_time and summary.end_time:
            summary.total_duration_ms = (
                summary.end_time - summary.start_time
            ).total_seconds() * 1000
    
    # ğŸ“ æ·»åŠ å®Œæˆæ¶ˆæ¯
    status_emoji = "ğŸ‰" if summary.overall_status == StepStatus.SUCCESS else "âš ï¸"
    completion_message = AIMessage(
        content=f"{status_emoji} æ‰€æœ‰æ­¥éª¤å·²å®Œæˆ\n" +
                f"â€¢ æ€»è®¡: {summary.total_steps} æ­¥\n" +
                f"â€¢ æˆåŠŸ: {summary.completed_steps} æ­¥\n" +
                f"â€¢ å¤±è´¥: {summary.failed_steps} æ­¥\n" +
                f"â€¢ æ€»è€—æ—¶: {summary.total_duration_ms:.0f}ms\n" +
                f"â€¢ Tokenæ¶ˆè€—: {summary.total_token_usage.total_tokens}"
    )

    return {
        "execution_summary": summary,
        "messages": [completion_message]
    }


async def replan_node(state: AgentState) -> dict:
    """
    é‡æ–°è§„åˆ’èŠ‚ç‚¹ - è¯„ä¼°æ‰§è¡Œç»“æœå¹¶å†³å®šä¸‹ä¸€æ­¥è¡ŒåŠ¨
    
    èŒè´£ï¼š
    1. è¯„ä¼°å·²æ‰§è¡Œæ­¥éª¤çš„ç»“æœ
    2. åˆ¤æ–­æ˜¯å¦å·²æ”¶é›†è¶³å¤Ÿä¿¡æ¯å¯ä»¥å›ç­”ç”¨æˆ·
    3. åˆ¤æ–­æ˜¯å¦éœ€è¦è°ƒæ•´è®¡åˆ’æˆ–é‡æ–°è§„åˆ’
    4. å†³å®šï¼šç»§ç»­æ‰§è¡Œ / é‡æ–°è§„åˆ’ / ç»“æŸå¹¶å“åº”
    
    â­ SOPæ¨¡å¼ï¼šåªæœ‰æ‰§è¡Œå®Œæ‰€æœ‰SOPæ­¥éª¤åæ‰å…è®¸replan
    """
    from langchain_core.messages import AIMessage, SystemMessage
    from langchain_core.output_parsers import JsonOutputParser
    from langchain_core.prompts import ChatPromptTemplate
    
    query = state.get("query", "")
    plan = state.get("plan", [])
    current_step = state.get("current_step", 0)
    step_results = state.get("step_results", [])
    is_sop_matched = state.get("is_sop_matched", False)
    
    # â­ æ£€æŸ¥æ˜¯å¦æ‰€æœ‰SOPæ­¥éª¤å·²æ‰§è¡Œå®Œæ¯•
    # é€šè¿‡æ¯”è¾ƒstep_resultsæ•°é‡å’ŒåŸå§‹plané•¿åº¦åˆ¤æ–­
    # å¦‚æœstep_resultsä¸­çš„æ­¥éª¤éƒ½æ¥è‡ªåŸå§‹planï¼Œè¯´æ˜è¿˜åœ¨SOPé˜¶æ®µ
    sop_completed = False
    if is_sop_matched and step_results:
        # æ£€æŸ¥æ˜¯å¦æœ‰step_index >= len(plan)çš„ç»“æœï¼ˆè¯´æ˜å·²ç»replanè¿‡ï¼‰
        max_step_index = max([r.step_index for r in step_results])
        # æˆ–è€…æ£€æŸ¥current_stepæ˜¯å¦å·²ç»åˆ°è¾¾æˆ–è¶…è¿‡åŸå§‹plané•¿åº¦
        if current_step >= len(plan):
            sop_completed = True
            print(f"[Replan] SOPå·²å…¨éƒ¨æ‰§è¡Œå®Œæ¯• ({len(plan)}æ­¥ï¼‰ï¼Œç°åœ¨å…è®¸replan")
    
    # å¦‚æœè¿˜æ²¡æœ‰æ‰§è¡Œä»»ä½•æ­¥éª¤ï¼Œç›´æ¥ç»§ç»­
    if not step_results:
        return {}
    
    # æ„å»ºå·²å®Œæˆæ­¥éª¤çš„æ‘˜è¦
    completed_steps_summary = []
    for result in step_results:
        status = "âœ… æˆåŠŸ" if result.status == "success" else "âŒ å¤±è´¥"
        summary = f"{status} æ­¥éª¤{result.step_index + 1}: {result.step_description}"
        if result.output_result:
            summary += f"\n   ç»“æœ: {result.output_result[:150]}"
        if result.error_message:
            summary += f"\n   é”™è¯¯: {result.error_message[:100]}"
        completed_steps_summary.append(summary)
    
    # å‰©ä½™æ­¥éª¤
    remaining_steps = plan[current_step:] if current_step < len(plan) else []
    
    # â­ ä»promptæ¨¡å—è·å–æç¤ºè¯æ¨¡æ¿ï¼ˆä¸å«é€»è¾‘ï¼‰
    from src.prompt.prompt import (
        get_replan_sop_in_progress_prompt_template,
        get_replan_general_prompt_template
    )
    
    # â­ ç»„è£…é€»è¾‘åœ¨è¿™é‡Œï¼ˆè°ƒç”¨æ–¹è´Ÿè´£ï¼‰
    if is_sop_matched and not sop_completed:
        # SOPæ‰§è¡Œä¸­ï¼šä½¿ç”¨SOPæ¨¡æ¿
        prompt_template = get_replan_sop_in_progress_prompt_template()
        replan_prompt = prompt_template.format(
            query=query,
            plan_list="\n".join([f"{i+1}. {step}" for i, step in enumerate(plan)]),
            completed_steps="\n".join(completed_steps_summary),
            remaining_steps="\n".join([f"{i+current_step+1}. {step}" for i, step in enumerate(remaining_steps)]) if remaining_steps else "æ— ",
            remaining_count=len(remaining_steps)
        )
    else:
        # éSOPæˆ–SOPå·²å®Œæˆï¼šä½¿ç”¨é€šç”¨æ¨¡æ¿
        prompt_template = get_replan_general_prompt_template()
        sop_note = "ï¼ˆSOPå·²å…¨éƒ¨æ‰§è¡Œå®Œæ¯•ï¼Œå¯ä»¥é‡æ–°è§„åˆ’ï¼‰" if is_sop_matched else ""
        replan_prompt = prompt_template.format(
            query=query,
            sop_note=sop_note,
            plan_list="\n".join([f"{i+1}. {step}" for i, step in enumerate(plan)]),
            completed_steps="\n".join(completed_steps_summary),
            remaining_steps="\n".join([f"{i+current_step+1}. {step}" for i, step in enumerate(remaining_steps)]) if remaining_steps else "æ— "
        )

    # è°ƒç”¨LLMè¿›è¡Œå†³ç­–ï¼ˆå¼‚æ­¥ï¼‰
    messages = [
        SystemMessage(content="ä½ æ˜¯ä¸€ä¸ªæ™ºèƒ½è§„åˆ’è¯„ä¼°åŠ©æ‰‹ï¼Œæ“…é•¿åˆ†ææ‰§è¡Œç»“æœå¹¶åšå‡ºåˆç†å†³ç­–ã€‚"),
        {"role": "user", "content": replan_prompt}
    ]
    
    try:
        result = await q_max.ainvoke(messages)
        
        # è§£æLLMå“åº”
        import json
        import re
        
        decision_data = None
        
        # ç­–ç•¥1: ç›´æ¥è§£æ result.content
        try:
            decision_data = json.loads(result.content)
        except json.JSONDecodeError:
            pass
        
        # ç­–ç•¥2: ä½¿ç”¨æ­£åˆ™æå– JSON å—
        if not decision_data:
            try:
                json_match = re.search(r'\{.*\}', result.content, re.DOTALL)
                if json_match:
                    json_str = json_match.group()
                    # å°è¯•ä¿®å¤å¸¸è§çš„ JSON æ ¼å¼é—®é¢˜
                    # 1. ç§»é™¤ JSON ä¸­çš„æ³¨é‡Š
                    json_str = re.sub(r'//.*?\n|/\*.*?\*/', '', json_str, flags=re.DOTALL)
                    # 2. ç§»é™¤å°¾éšé€—å·
                    json_str = re.sub(r',(\s*[}\]])', r'\1', json_str)
                    decision_data = json.loads(json_str)
            except (json.JSONDecodeError, AttributeError) as e:
                print(f"[Replan] JSON è§£æå¤±è´¥: {e}")
        
        # ç­–ç•¥3: ä½¿ç”¨ LangChain çš„ JsonOutputParser å¼ºåˆ¶è§£æ
        if not decision_data:
            try:
                parser = JsonOutputParser()
                decision_data = parser.invoke(result)
            except Exception as e:
                print(f"[Replan] JsonOutputParser å¤±è´¥: {e}")
        
        # æœ€åçš„å…œåº•: é»˜è®¤ç»§ç»­æ‰§è¡Œ
        if not decision_data:
            print(f"[Replan] æ— æ³•è§£æå“åº”ï¼ŒåŸå§‹å†…å®¹: {result.content[:200]}")
            decision_data = {
                "decision": "continue",
                "reasoning": "æ— æ³•è§£æLLMå“åº”ï¼Œé»˜è®¤ç»§ç»­æ‰§è¡Œ"
            }
        
        decision = decision_data.get("decision", "continue")
        reasoning = decision_data.get("reasoning", "")
        
        print(f"\n[Replan] å†³ç­–: {decision}")
        print(f"[Replan] æ¨ç†: {reasoning}")
        
        messages_to_add = []
        
        # æ ¹æ®å†³ç­–è¿”å›ä¸åŒçš„ç»“æœ
        if decision == "respond":
            # å·²æœ‰è¶³å¤Ÿä¿¡æ¯ï¼Œç”Ÿæˆæœ€ç»ˆå“åº”
            response_text = decision_data.get("response", "")
            
            response_message = AIMessage(
                content=f"ğŸ’¡ å·²æ”¶é›†è¶³å¤Ÿä¿¡æ¯ï¼Œç”Ÿæˆæœ€ç»ˆç­”æ¡ˆ\n{response_text}"
            )
            messages_to_add.append(response_message)
            
            return {
                "response": response_text,
                "messages": messages_to_add,
                # æ ‡è®°ä¸ºå®Œæˆï¼Œåœæ­¢ç»§ç»­æ‰§è¡Œ
                "current_step": len(plan)  # è®¾ç½®ä¸ºè®¡åˆ’é•¿åº¦ï¼Œè§¦å‘å®Œæˆ
            }
        
        elif decision == "replan":
            # éœ€è¦é‡æ–°è§„åˆ’
            new_plan = decision_data.get("new_plan", [])
            
            replan_message = AIMessage(
                content=f"ğŸ”„ éœ€è¦è°ƒæ•´è®¡åˆ’\nåŸå› : {reasoning}\næ–°è®¡åˆ’:\n" +
                        "\n".join([f"{i+1}. {step}" for i, step in enumerate(new_plan)])
            )
            messages_to_add.append(replan_message)
            
            return {
                "plan": new_plan,
                "current_step": 0,  # é‡ç½®åˆ°ç¬¬ä¸€æ­¥
                "messages": messages_to_add
            }
        
        else:  # continue
            # ç»§ç»­æ‰§è¡Œå‰©ä½™è®¡åˆ’
            continue_message = AIMessage(
                content=f"â–¶ï¸ ç»§ç»­æ‰§è¡Œå‰©ä½™è®¡åˆ’\nåŸå› : {reasoning}"
            )
            messages_to_add.append(continue_message)
            
            return {
                "messages": messages_to_add
            }
    
    except Exception as e:
        print(f"[Replan] é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
        
        # å‡ºé”™æ—¶é»˜è®¤ç»§ç»­æ‰§è¡Œ
        error_message = AIMessage(
            content=f"âš ï¸ è¯„ä¼°è¿‡ç¨‹å‡ºé”™ï¼Œç»§ç»­æ‰§è¡ŒåŸè®¡åˆ’\né”™è¯¯: {str(e)[:100]}"
        )
        
        return {
            "messages": [error_message]
        }

    """
    é‡æ–°è§„åˆ’èŠ‚ç‚¹ - è¯„ä¼°æ‰§è¡Œç»“æœå¹¶å†³å®šä¸‹ä¸€æ­¥è¡ŒåŠ¨
    
    èŒè´£ï¼š
    1. è¯„ä¼°å·²æ‰§è¡Œæ­¥éª¤çš„ç»“æœ
    2. åˆ¤æ–­æ˜¯å¦å·²æ”¶é›†è¶³å¤Ÿä¿¡æ¯å¯ä»¥å›ç­”ç”¨æˆ·
    3. åˆ¤æ–­æ˜¯å¦éœ€è¦è°ƒæ•´è®¡åˆ’æˆ–é‡æ–°è§„åˆ’
    4. å†³å®šï¼šç»§ç»­æ‰§è¡Œ / é‡æ–°è§„åˆ’ / ç»“æŸå¹¶å“åº”
    
    â­ SOPæ¨¡å¼ï¼šåªæœ‰æ‰§è¡Œå®Œæ‰€æœ‰SOPæ­¥éª¤åæ‰å…è®¸replan
    """
    from langchain_core.messages import AIMessage, SystemMessage
    from langchain_core.output_parsers import JsonOutputParser
    from langchain_core.prompts import ChatPromptTemplate
    
    query = state.get("query", "")
    plan = state.get("plan", [])
    current_step = state.get("current_step", 0)
    step_results = state.get("step_results", [])
    is_sop_matched = state.get("is_sop_matched", False)
    
    # â­ æ£€æŸ¥æ˜¯å¦æ‰€æœ‰SOPæ­¥éª¤å·²æ‰§è¡Œå®Œæ¯•
    # é€šè¿‡æ¯”è¾ƒstep_resultsæ•°é‡å’ŒåŸå§‹plané•¿åº¦åˆ¤æ–­
    # å¦‚æœstep_resultsä¸­çš„æ­¥éª¤éƒ½æ¥è‡ªåŸå§‹planï¼Œè¯´æ˜è¿˜åœ¨SOPé˜¶æ®µ
    sop_completed = False
    if is_sop_matched and step_results:
        # æ£€æŸ¥æ˜¯å¦æœ‰step_index >= len(plan)çš„ç»“æœï¼ˆè¯´æ˜å·²ç»replanè¿‡ï¼‰
        max_step_index = max([r.step_index for r in step_results])
        # æˆ–è€…æ£€æŸ¥current_stepæ˜¯å¦å·²ç»åˆ°è¾¾æˆ–è¶…è¿‡åŸå§‹plané•¿åº¦
        if current_step >= len(plan):
            sop_completed = True
            print(f"[Replan] SOPå·²å…¨éƒ¨æ‰§è¡Œå®Œæ¯• ({len(plan)}æ­¥ï¼‰ï¼Œç°åœ¨å…è®¸replan")
    
    # å¦‚æœè¿˜æ²¡æœ‰æ‰§è¡Œä»»ä½•æ­¥éª¤ï¼Œç›´æ¥ç»§ç»­
    if not step_results:
        return {}
    
    # æ„å»ºå·²å®Œæˆæ­¥éª¤çš„æ‘˜è¦
    completed_steps_summary = []
    for result in step_results:
        status = "âœ… æˆåŠŸ" if result.status == "success" else "âŒ å¤±è´¥"
        summary = f"{status} æ­¥éª¤{result.step_index + 1}: {result.step_description}"
        if result.output_result:
            summary += f"\n   ç»“æœ: {result.output_result[:150]}"
        if result.error_message:
            summary += f"\n   é”™è¯¯: {result.error_message[:100]}"
        completed_steps_summary.append(summary)
    
    # å‰©ä½™æ­¥éª¤
    remaining_steps = plan[current_step:] if current_step < len(plan) else []
    
    # â­ ä»promptæ¨¡å—è·å–æç¤ºè¯æ¨¡æ¿ï¼ˆä¸å«é€»è¾‘ï¼‰
    from src.prompt.prompt import (
        get_replan_sop_in_progress_prompt_template,
        get_replan_general_prompt_template
    )
    
    # â­ ç»„è£…é€»è¾‘åœ¨è¿™é‡Œï¼ˆè°ƒç”¨æ–¹è´Ÿè´£ï¼‰
    if is_sop_matched and not sop_completed:
        # SOPæ‰§è¡Œä¸­ï¼šä½¿ç”¨SOPæ¨¡æ¿
        prompt_template = get_replan_sop_in_progress_prompt_template()
        replan_prompt = prompt_template.format(
            query=query,
            plan_list="\n".join([f"{i+1}. {step}" for i, step in enumerate(plan)]),
            completed_steps="\n".join(completed_steps_summary),
            remaining_steps="\n".join([f"{i+current_step+1}. {step}" for i, step in enumerate(remaining_steps)]) if remaining_steps else "æ— ",
            remaining_count=len(remaining_steps)
        )
    else:
        # éSOPæˆ–SOPå·²å®Œæˆï¼šä½¿ç”¨é€šç”¨æ¨¡æ¿
        prompt_template = get_replan_general_prompt_template()
        sop_note = "ï¼ˆSOPå·²å…¨éƒ¨æ‰§è¡Œå®Œæ¯•ï¼Œå¯ä»¥é‡æ–°è§„åˆ’ï¼‰" if is_sop_matched else ""
        replan_prompt = prompt_template.format(
            query=query,
            sop_note=sop_note,
            plan_list="\n".join([f"{i+1}. {step}" for i, step in enumerate(plan)]),
            completed_steps="\n".join(completed_steps_summary),
            remaining_steps="\n".join([f"{i+current_step+1}. {step}" for i, step in enumerate(remaining_steps)]) if remaining_steps else "æ— "
        )

    # è°ƒç”¨LLMè¿›è¡Œå†³ç­–
    messages = [
        SystemMessage(content="ä½ æ˜¯ä¸€ä¸ªæ™ºèƒ½è§„åˆ’è¯„ä¼°åŠ©æ‰‹ï¼Œæ“…é•¿åˆ†ææ‰§è¡Œç»“æœå¹¶åšå‡ºåˆç†å†³ç­–ã€‚"),
        {"role": "user", "content": replan_prompt}
    ]
    
    try:
        result = q_max.invoke(messages)
        
        # è§£æLLMå“åº”
        import json
        import re
        
        decision_data = None
        
        # ç­–ç•¥1: ç›´æ¥è§£æ result.content
        try:
            decision_data = json.loads(result.content)
        except json.JSONDecodeError:
            pass
        
        # ç­–ç•¥2: ä½¿ç”¨æ­£åˆ™æå– JSON å—
        if not decision_data:
            try:
                json_match = re.search(r'\{.*\}', result.content, re.DOTALL)
                if json_match:
                    json_str = json_match.group()
                    # å°è¯•ä¿®å¤å¸¸è§çš„ JSON æ ¼å¼é—®é¢˜
                    # 1. ç§»é™¤ JSON ä¸­çš„æ³¨é‡Š
                    json_str = re.sub(r'//.*?\n|/\*.*?\*/', '', json_str, flags=re.DOTALL)
                    # 2. ç§»é™¤å°¾éšé€—å·
                    json_str = re.sub(r',(\s*[}\]])', r'\1', json_str)
                    decision_data = json.loads(json_str)
            except (json.JSONDecodeError, AttributeError) as e:
                print(f"[Replan] JSON è§£æå¤±è´¥: {e}")
        
        # ç­–ç•¥3: ä½¿ç”¨ LangChain çš„ JsonOutputParser å¼ºåˆ¶è§£æ
        if not decision_data:
            try:
                parser = JsonOutputParser()
                decision_data = parser.invoke(result)
            except Exception as e:
                print(f"[Replan] JsonOutputParser å¤±è´¥: {e}")
        
        # æœ€åçš„å…œåº•: é»˜è®¤ç»§ç»­æ‰§è¡Œ
        if not decision_data:
            print(f"[Replan] æ— æ³•è§£æå“åº”ï¼ŒåŸå§‹å†…å®¹: {result.content[:200]}")
            decision_data = {
                "decision": "continue",
                "reasoning": "æ— æ³•è§£æLLMå“åº”ï¼Œé»˜è®¤ç»§ç»­æ‰§è¡Œ"
            }
        
        decision = decision_data.get("decision", "continue")
        reasoning = decision_data.get("reasoning", "")
        
        print(f"\n[Replan] å†³ç­–: {decision}")
        print(f"[Replan] æ¨ç†: {reasoning}")
        
        messages_to_add = []
        
        # æ ¹æ®å†³ç­–è¿”å›ä¸åŒçš„ç»“æœ
        if decision == "respond":
            # å·²æœ‰è¶³å¤Ÿä¿¡æ¯ï¼Œç”Ÿæˆæœ€ç»ˆå“åº”
            response_text = decision_data.get("response", "")
            
            response_message = AIMessage(
                content=f"ğŸ’¡ å·²æ”¶é›†è¶³å¤Ÿä¿¡æ¯ï¼Œç”Ÿæˆæœ€ç»ˆç­”æ¡ˆ\n{response_text}"
            )
            messages_to_add.append(response_message)
            
            return {
                "response": response_text,
                "messages": messages_to_add,
                # æ ‡è®°ä¸ºå®Œæˆï¼Œåœæ­¢ç»§ç»­æ‰§è¡Œ
                "current_step": len(plan)  # è®¾ç½®ä¸ºè®¡åˆ’é•¿åº¦ï¼Œè§¦å‘å®Œæˆ
            }
        
        elif decision == "replan":
            # éœ€è¦é‡æ–°è§„åˆ’
            new_plan = decision_data.get("new_plan", [])
            
            replan_message = AIMessage(
                content=f"ğŸ”„ éœ€è¦è°ƒæ•´è®¡åˆ’\nåŸå› : {reasoning}\næ–°è®¡åˆ’:\n" +
                        "\n".join([f"{i+1}. {step}" for i, step in enumerate(new_plan)])
            )
            messages_to_add.append(replan_message)
            
            return {
                "plan": new_plan,
                "current_step": 0,  # é‡ç½®åˆ°ç¬¬ä¸€æ­¥
                "messages": messages_to_add
            }
        
        else:  # continue
            # ç»§ç»­æ‰§è¡Œå‰©ä½™è®¡åˆ’
            continue_message = AIMessage(
                content=f"â–¶ï¸ ç»§ç»­æ‰§è¡Œå‰©ä½™è®¡åˆ’\nåŸå› : {reasoning}"
            )
            messages_to_add.append(continue_message)
            
            return {
                "messages": messages_to_add
            }
    
    except Exception as e:
        print(f"[Replan] é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
        
        # å‡ºé”™æ—¶é»˜è®¤ç»§ç»­æ‰§è¡Œ
        error_message = AIMessage(
            content=f"âš ï¸ è¯„ä¼°è¿‡ç¨‹å‡ºé”™ï¼Œç»§ç»­æ‰§è¡ŒåŸè®¡åˆ’\né”™è¯¯: {str(e)[:100]}"
        )
        
        return {
            "messages": [error_message]
        }
