import asyncio
from langgraph.types import Command, interrupt
from langchain_core.messages import SystemMessage, AIMessage, HumanMessage
from langchain.agents import create_agent

from langchain_core.output_parsers import JsonOutputParser
from langchain_core.prompts import PromptTemplate, ChatPromptTemplate
from datetime import datetime
import time

from src.config.llm import q_max, get_gpt_model, mt_llm, q_plus, get_claude_model
from src.graph_state import AgentState, Plan
from src.tools import (
    ALL_TOOLS,
    check_low_star_merchant, 
    check_sensitive_merchant,
    search_user_access_history,
    restore_user_scene,
    analyze_recall_chain,
    parse_user_query_params
)
from src.models.execution_result import (
    StepExecutionResult,
    StepStatus,
    ToolCall,
    PlanExecutionSummary,
    TokenUsage
)


async def planning_node(state: AgentState):
    """ç”Ÿæˆæ‰§è¡Œè®¡åˆ’ - æ ¹æ®intentåŠ¨æ€é€‰æ‹©prompt"""
    from langchain_core.messages import AIMessage
    from src.config.sop_loader import get_sop_loader
    
    rewritten_query = state['rewritten_query']
    intent = state.get('intent', 'default')
    
    # â­ ä»SOPLoaderè·å–planning prompt
    sop_loader = get_sop_loader()
    plan_prompt = sop_loader.get_planning_prompt(intent)

    plan_parser = JsonOutputParser(pydantic_object=Plan)
    format_instructions = plan_parser.get_format_instructions()

    from src.prompt.prompt_loader import get_prompt
    prompt = ChatPromptTemplate.from_messages([
        SystemMessage(content=get_prompt("system_prompt")),
        SystemMessage(content=plan_prompt) if plan_prompt else "",
        HumanMessage(content=rewritten_query),
        SystemMessage(content=f"æ‰€æœ‰å›å¤å¿…é¡»éµå¾ªä»¥ä¸‹æ ¼å¼ï¼š\n{format_instructions}"),
    ])
    chain = prompt | get_gpt_model("gpt-4.1").bind_tools(ALL_TOOLS) | JsonOutputParser()
    result = await chain.ainvoke({})
    steps = result.get('steps', [])
    
    # ğŸ“ æ·»åŠ è®¡åˆ’ç”Ÿæˆæ¶ˆæ¯
    plan_message = AIMessage(
        content=f"ğŸ“‹ [{intent}] å·²ç”Ÿæˆæ‰§è¡Œè®¡åˆ’ï¼Œå…±{len(steps)}ä¸ªæ­¥éª¤:\n" + 
                "\n".join([f"{i+1}. {step}" for i, step in enumerate(steps)])
    )
    
    return {
        "plan": steps,
        "current_step": 0,
        "messages": [plan_message]
    }


async def plan_executor_node(state: AgentState):
    """å¢å¼ºç‰ˆè®¡åˆ’æ‰§è¡ŒèŠ‚ç‚¹ - æ”¯æŒHuman-in-the-Loopï¼ˆå¼‚æ­¥ç‰ˆæœ¬ï¼‰"""
    plan = state.get("plan", [])
    current_step = state.get("current_step", 0)
    
    # æ£€æŸ¥æ˜¯å¦å·²å®Œæˆæ‰€æœ‰æ­¥éª¤
    if current_step >= len(plan):
        print(f"[PlanExecutor] æ‰€æœ‰æ­¥éª¤å·²å®Œæˆ")
        return finalize_execution(state)
    
    step_description = plan[current_step]
    
    # åˆå§‹åŒ–æ­¥éª¤æ‰§è¡Œç»“æœ
    step_result = StepExecutionResult(
        step_index=current_step,
        step_description=step_description,
        status=StepStatus.RUNNING,
        start_time=datetime.now()
    )

    
    # Added for new logic
    messages_to_add = []
    
    # â­ ä½¿ç”¨ state å­—æ®µåˆ¤æ–­æ˜¯å¦å¤„äºä¸­æ–­æ¢å¤çŠ¶æ€ï¼ˆæ›´å¯é ï¼‰
    user_input = None
    is_resuming = state.get("need_clarification", False)
    
    if is_resuming:
        # å¤„äºä¸­æ–­çŠ¶æ€ï¼ŒæŸ¥æ‰¾ç”¨æˆ·çš„å›å¤
        messages = state.get("messages", [])
        
        # ä»åå¾€å‰æ‰¾æœ€è¿‘çš„ HumanMessage
        for i in range(len(messages) - 1, -1, -1):
            msg = messages[i]
            if isinstance(msg, HumanMessage):
                user_input = msg.content
                print(f"[Executor] æ£€æµ‹åˆ°ç”¨æˆ·å›å¤ï¼ˆæ¢å¤æ¨¡å¼ï¼‰: {user_input}")
                break
        
        if user_input:
            # æ·»åŠ æ¢å¤æ¶ˆæ¯
            resume_message = AIMessage(
                content=f"â–¶ï¸ æ”¶åˆ°æ‚¨çš„å›å¤ï¼Œç»§ç»­æ‰§è¡Œæ­¥éª¤ {current_step + 1}"
            )
            messages_to_add.append(resume_message)
    
    if not is_resuming:
        # é¦–æ¬¡æ‰§è¡Œæ­¤æ­¥éª¤ï¼Œæ·»åŠ å¼€å§‹æ¶ˆæ¯
        start_message = AIMessage(
            content=f"ğŸ”„ å¼€å§‹æ‰§è¡Œæ­¥éª¤ {current_step + 1}/{len(plan)}: {step_description}"
        )
        messages_to_add.append(start_message)
    
    print(f"[æ‰§è¡Œ] æ­¥éª¤ {current_step + 1}/{len(plan)}: {step_description}")
    
    # å‡†å¤‡Agentç³»ç»Ÿæç¤ºï¼ˆä¼ é€’å½“å‰è½®æ¬¡çš„æ–°æ¶ˆæ¯ï¼‰
    system_prompt = build_executor_prompt(state, current_step, step_description, messages_to_add)
    
    # â­ è·å– MCP å·¥å…·å¹¶åˆå¹¶
    from src.mcp import get_mcp_manager

    mcp_manager = get_mcp_manager()
    mcp_tools = mcp_manager.get_all_tools()

    print(f"[MCP] å·²åŠ è½½ {len(mcp_tools)} ä¸ª MCP å·¥å…·")

    # åˆå¹¶é™æ€å·¥å…·å’Œ MCP å·¥å…·
    all_tools = ALL_TOOLS + mcp_tools

    # åˆ›å»ºAgent
    agent = create_agent(
        system_prompt=system_prompt,
        # model=mt_llm("gpt-4.1"),
        model=get_gpt_model(),
        tools=all_tools,  # â­ ä½¿ç”¨åˆå¹¶åçš„å·¥å…·åˆ—è¡¨
    )
    
    # æ‰§è¡Œï¼ˆå¼‚æ­¥ï¼‰
    start_exec = time.time()
    # â­ æ„å»ºè¾“å…¥æ¶ˆæ¯ï¼šå¦‚æœæœ‰ç”¨æˆ·å›å¤ï¼Œéœ€è¦åœ¨å½“å‰è½®æ¬¡ä¸­ä¼ é€’ç»™ Agent
    # è™½ç„¶ system_prompt åŒ…å«å†å²ï¼Œä½† Agent éœ€è¦åœ¨ messages å‚æ•°ä¸­æ¥æ”¶å½“å‰ç”¨æˆ·è¾“å…¥
    input_messages = []
    if user_input:
        input_messages.append(HumanMessage(content=user_input))
    
    execution_result = await agent.ainvoke({"messages": input_messages})

    exec_duration = (time.time() - start_exec) * 1000
    # â­ æå– Token Usage
    token_usage = TokenUsage()
    if "messages" in execution_result and execution_result["messages"]:
        last_msg = execution_result["messages"][-1]
        if hasattr(last_msg, "response_metadata"):
            usage_data = last_msg.response_metadata.get("token_usage", {})
            if usage_data:
                token_usage = TokenUsage(
                    prompt_tokens=usage_data.get("prompt_tokens", 0),
                    completion_tokens=usage_data.get("completion_tokens", 0),
                    total_tokens=usage_data.get("total_tokens", 0)
                )
                print(f"[èµ„æº] Tokenæ¶ˆè€—: {token_usage.total_tokens} (Prompt: {token_usage.prompt_tokens}, Completion: {token_usage.completion_tokens})")
    
    output = execution_result["messages"][-1].content
    
    # â­ æ£€æŸ¥æ˜¯å¦éœ€è¦è¯¢é—®ç”¨æˆ·
    if "ask_human" in output.lower():
        print(f"[ä¸­æ–­] æ­¥éª¤ {current_step + 1} éœ€è¦ç”¨æˆ·è¾“å…¥")
        
        # æå–é—®é¢˜ï¼ˆAgentåº”è¯¥åœ¨è¾“å‡ºä¸­è¯´æ˜éœ€è¦ä»€ä¹ˆä¿¡æ¯ï¼‰
        question = output.replace("ask_human", "").strip()
        if not question:
            question = "è¯·æä¾›æ‰§è¡Œæ­¤æ­¥éª¤æ‰€éœ€çš„ä¿¡æ¯"
        
        # æ›´æ–°æ­¥éª¤çŠ¶æ€ä¸ºéœ€è¦æ¾„æ¸…
        # step_result.status = StepStatus.NEED_CLARIFICATION
        # step_result.interrupt_question = question
        # step_result.end_time = datetime.now()
        # step_result.duration_ms = exec_duration
        
        # æ·»åŠ ä¸­æ–­æ¶ˆæ¯
        interrupt_message = AIMessage(
            content=f"â¸ï¸ æ­¥éª¤ {current_step + 1} éœ€è¦æ›´å¤šä¿¡æ¯\n{question}"
        )
        messages_to_add.append(interrupt_message)
        
        # â­ ä¸­æ–­ï¼šä¸å¢åŠ current_stepï¼Œä¿æŒåœ¨å½“å‰æ­¥éª¤
        return Command(goto="ask_human", update={
            "response": question,
            "return_to": "plan_executor",
            "need_clarification": True,
            "step_results": [step_result],
            "messages": messages_to_add,
            # current_step ä¸å˜ï¼ç”¨æˆ·å›å¤åä¼šé‡æ–°æ‰§è¡Œè¿™ä¸€æ­¥
        })
    
    # æ­£å¸¸æ‰§è¡Œå®Œæˆ
    # æå–å·¥å…·è°ƒç”¨ä¿¡æ¯
    tool_calls = extract_tool_calls(execution_result)
    
    # æ›´æ–°ç»“æœ
    step_result.status = StepStatus.SUCCESS
    step_result.end_time = datetime.now()
    step_result.duration_ms = exec_duration
    step_result.token_usage = token_usage
    step_result.agent_response = str(output)
    step_result.output_result = output[:500] if output else ""
    
    # â­ æ‰“å°æˆåŠŸæ—¥å¿—å’Œå·¥å…·ç»“æœ
    print(f"[æˆåŠŸ] æ­¥éª¤ {current_step + 1} å®Œæˆ,è€—æ—¶ {exec_duration:.2f}ms")

    # ğŸ“ æ·»åŠ æˆåŠŸæ¶ˆæ¯
    result_summary = step_result.output_result[:200] if step_result.output_result else "æ‰§è¡Œå®Œæˆ"
    tools_used = f" (ä½¿ç”¨äº†{len(tool_calls)}ä¸ªå·¥å…·)" if tool_calls else ""
    
    success_message = AIMessage(
        content=f"âœ… æ­¥éª¤ {current_step + 1} å®Œæˆ{tools_used}\n{result_summary}"
    )
    messages_to_add.append(success_message)
    
    # â­ æˆåŠŸåæ‰å¢åŠ current_step
    return {
        "current_step": current_step + 1,
        "step_results": [step_result],
        "messages": messages_to_add,
        "need_clarification": False,
        "past_steps": [(step_description, step_result.agent_response)]
    }




def format_message_history(messages: list, filter_types: list = None) -> str:
    """
    æ ¼å¼åŒ–æ¶ˆæ¯å†å²ä¸ºå­—ç¬¦ä¸²
    
    Args:
        messages: æ¶ˆæ¯åˆ—è¡¨
        filter_types: éœ€è¦åŒ…å«çš„æ¶ˆæ¯ç±»å‹ï¼Œé»˜è®¤ä¸º ['human', 'ai']
        
    Returns:
        æ ¼å¼åŒ–åçš„æ¶ˆæ¯å†å²å­—ç¬¦ä¸²
    """
    if not messages:
        return ""
    
    if filter_types is None:
        filter_types = ['human', 'ai']
    
    return "\n".join([
        f"{msg.type}: {msg.content}" 
        for msg in messages 
        if msg.type in filter_types
    ])


def build_executor_prompt(state: AgentState, step_index: int, task: str, messages_to_add: list = None) -> str:
    """æ„å»ºæ‰§è¡Œå™¨æç¤ºè¯
    
    Args:
        state: å½“å‰çŠ¶æ€
        step_index: æ­¥éª¤ç´¢å¼•
        task: ä»»åŠ¡æè¿°
        messages_to_add: å½“å‰è½®æ¬¡æ–°å¢çš„æ¶ˆæ¯ï¼ˆç”¨äºåˆå¹¶åˆ°å¯¹è¯å†å²ï¼‰
    """
    from src.prompt.prompt_loader import get_prompt
    
    previous_results = state.get("step_results", [])
    context = ""
    if previous_results:
        context = "\n".join([
            f"æ­¥éª¤{i+1}: {r.step_description} -> {r.output_result or 'æ— ç»“æœ'}"
            for i, r in enumerate(previous_results[-3:])  # åªæ˜¾ç¤ºæœ€è¿‘3æ­¥
        ])

    # â­ åˆå¹¶ç°æœ‰æ¶ˆæ¯å’Œå½“å‰è½®æ¬¡æ–°å¢çš„æ¶ˆæ¯
    messages = state.get("messages", []).copy()
    if messages_to_add:
        messages.extend(messages_to_add)
    
    chat_history_str = format_message_history(messages)
    
    # ğŸ” è°ƒè¯•è¾“å‡º
    print(f"\n[DEBUG] build_executor_prompt è°ƒè¯•ä¿¡æ¯:")
    print(f"  åŸå§‹æ¶ˆæ¯æ•°: {len(state.get('messages', []))}")
    print(f"  æ–°å¢æ¶ˆæ¯æ•°: {len(messages_to_add) if messages_to_add else 0}")
    print(f"  åˆå¹¶åæ€»æ•°: {len(messages)}")
    print(f"  å¯¹è¯å†å²:\n{chat_history_str if chat_history_str else '(æ— )'}")

    # ä» YAML åŠ è½½æç¤ºè¯æ¨¡æ¿
    executor_prompt_template = get_prompt("plan_executor")
    
    prompt = executor_prompt_template.format(
        query=state.get('rewritten_query', ''),
        step_index=step_index + 1,
        task=task,
        context=context or 'æ— ',
        chat_history=chat_history_str or 'æ— '
    )
    
    # ğŸ” æ‰“å°å®Œæ•´çš„ system_prompt
    print(f"\n[DEBUG] System Prompt:\n{prompt}\n")
    
    return prompt



def extract_tool_calls(result: dict) -> list:
    """ä»Agentç»“æœä¸­æå–å·¥å…·è°ƒç”¨ä¿¡æ¯"""
    tool_calls_list = []
    messages = result.get("messages", [])

    for msg in messages:
        if hasattr(msg, "tool_calls") and msg.tool_calls:
            for tc in msg.tool_calls:
                tool_calls_list.append(ToolCall(
                    tool_name=tc.get("name", "unknown"),
                    arguments=tc.get("args", {}),
                    result=tc.get("result"),
                    error=tc.get("error")
                ))

    return tool_calls_list


def extract_output(result: dict) -> str:
    """æå–è¾“å‡ºç»“æœ"""
    if "output" in result:
        return str(result["output"])
    if "messages" in result and result["messages"]:
        last_msg = result["messages"][-1]
        if hasattr(last_msg, "content"):
            return last_msg.content
    return ""


def finalize_execution(state: AgentState) -> dict:
    """å®Œæˆæ‰§è¡Œ,ç”Ÿæˆæ‘˜è¦"""
    from langchain_core.messages import AIMessage
    
    step_results = state.get("step_results", [])

    summary = PlanExecutionSummary(
        # plan_id=state.get("thread_id", "unknown"),
        query=state.get("query", ""),
        intent=state.get("intent"),
        is_sop=state.get("is_sop_matched", False),
        total_steps=len(state.get("plan", [])),
        plan_steps=state.get("plan", []),
        completed_steps=len([r for r in step_results if r.status == StepStatus.SUCCESS]),
        failed_steps=len([r for r in step_results if r.status == StepStatus.FAILED]),
        skipped_steps=len([r for r in step_results if r.status == StepStatus.SKIPPED]),
        overall_status=StepStatus.SUCCESS if all(
            r.status == StepStatus.SUCCESS for r in step_results
        ) else StepStatus.FAILED,
        final_response=state.get("response", "")
    )

    # â­ èšåˆ Token Usage
    total_tokens = TokenUsage()
    for res in step_results:
        if res.token_usage:
            total_tokens.add(res.token_usage)
    summary.total_token_usage = total_tokens

    if step_results:
        summary.start_time = step_results[0].start_time
        summary.end_time = step_results[-1].end_time
        if summary.start_time and summary.end_time:
            summary.total_duration_ms = (
                summary.end_time - summary.start_time
            ).total_seconds() * 1000
    
    # ğŸ“ æ·»åŠ å®Œæˆæ¶ˆæ¯
    status_emoji = "ğŸ‰" if summary.overall_status == StepStatus.SUCCESS else "âš ï¸"
    completion_message = AIMessage(
        content=f"{status_emoji} æ‰€æœ‰æ­¥éª¤å·²å®Œæˆ\n" +
                f"â€¢ æ€»è®¡: {summary.total_steps} æ­¥\n" +
                f"â€¢ æˆåŠŸ: {summary.completed_steps} æ­¥\n" +
                f"â€¢ å¤±è´¥: {summary.failed_steps} æ­¥\n" +
                f"â€¢ æ€»è€—æ—¶: {summary.total_duration_ms:.0f}ms\n" +
                f"â€¢ Tokenæ¶ˆè€—: {summary.total_token_usage.total_tokens}"
    )

    return {
        "execution_summary": summary,
        "messages": [completion_message]
    }


async def replan_node(state: AgentState) -> dict:
    """
    é‡æ–°è§„åˆ’èŠ‚ç‚¹ - è¯„ä¼°æ‰§è¡Œç»“æœå¹¶å†³å®šä¸‹ä¸€æ­¥è¡ŒåŠ¨
    
    èŒè´£ï¼š
    1. è¯„ä¼°å·²æ‰§è¡Œæ­¥éª¤çš„ç»“æœ
    2. åˆ¤æ–­æ˜¯å¦å·²æ”¶é›†è¶³å¤Ÿä¿¡æ¯å¯ä»¥å›ç­”ç”¨æˆ·
    3. åˆ¤æ–­æ˜¯å¦éœ€è¦è°ƒæ•´è®¡åˆ’æˆ–é‡æ–°è§„åˆ’
    4. å†³å®šï¼šç»§ç»­æ‰§è¡Œ / é‡æ–°è§„åˆ’ / ç»“æŸå¹¶å“åº”
    
    â­ SOPæ¨¡å¼ï¼šåªæœ‰æ‰§è¡Œå®Œæ‰€æœ‰SOPæ­¥éª¤åæ‰å…è®¸replan
    """

    query = state.get("rewritten_query", "")
    plan = state.get("plan", [])
    current_step = state.get("current_step", 0)
    step_results = state.get("step_results", [])
    is_sop_matched = state.get("is_sop_matched", False)
    
    sop_completed = False
    # åˆ¤æ–­æ˜¯å¦æ‰§è¡Œå®Œè®¡åˆ’
    if is_sop_matched and step_results:
        if current_step >= len(plan):
            sop_completed = True
            print(f"[Replan] SOPå·²å…¨éƒ¨æ‰§è¡Œå®Œæ¯• ({len(plan)}æ­¥ï¼‰ï¼Œç°åœ¨å…è®¸replan")
    
    # å¦‚æœè¿˜æ²¡æœ‰æ‰§è¡Œä»»ä½•æ­¥éª¤ï¼Œç›´æ¥ç»§ç»­
    if not step_results:
        return {}
    
    # æ„å»ºå·²å®Œæˆæ­¥éª¤çš„æ‘˜è¦
    completed_steps_summary = []
    for result in step_results:
        status = "âœ… æˆåŠŸ" if result.status == "success" else "âŒ å¤±è´¥"
        summary = f"{status} æ­¥éª¤{result.step_index + 1}: {result.step_description}"
        if result.output_result:
            summary += f"\n   ç»“æœ: {result.output_result[:150]}"
        if result.error_message:
            summary += f"\n   é”™è¯¯: {result.error_message[:100]}"
        completed_steps_summary.append(summary)
    
    # å‰©ä½™æ­¥éª¤
    remaining_steps = plan[current_step:] if current_step < len(plan) else []
    
    # â­ ä»prompt_loaderè·å–æç¤ºè¯æ¨¡æ¿
    from src.prompt.prompt_loader import get_prompt
    
    # â­ ç»„è£…é€»è¾‘åœ¨è¿™é‡Œï¼ˆè°ƒç”¨æ–¹è´Ÿè´£ï¼‰
    if is_sop_matched and not sop_completed:
        # SOPæ‰§è¡Œä¸­ï¼šä½¿ç”¨SOPæ¨¡æ¿
        prompt_template = get_prompt("replan_sop_in_progress")
        replan_prompt = prompt_template.format(
            query=query,
            plan_list="\n".join([f"{i+1}. {step}" for i, step in enumerate(plan)]),
            completed_steps="\n".join(completed_steps_summary),
            remaining_steps="\n".join([f"{i+current_step+1}. {step}" for i, step in enumerate(remaining_steps)]) if remaining_steps else "æ— ",
            remaining_count=len(remaining_steps)
        )
    else:
        # éSOPæˆ–SOPå·²å®Œæˆï¼šä½¿ç”¨é€šç”¨æ¨¡æ¿
        prompt_template = get_prompt("replan_general")
        sop_note = "ï¼ˆSOPå·²å…¨éƒ¨æ‰§è¡Œå®Œæ¯•ï¼Œå¯ä»¥é‡æ–°è§„åˆ’ï¼‰" if is_sop_matched else ""
        replan_prompt = prompt_template.format(
            query=query,
            sop_note=sop_note,
            plan_list="\n".join([f"{i+1}. {step}" for i, step in enumerate(plan)]),
            completed_steps="\n".join(completed_steps_summary),
            remaining_steps="\n".join([f"{i+current_step+1}. {step}" for i, step in enumerate(remaining_steps)]) if remaining_steps else "æ— "
        )

    # è°ƒç”¨LLMè¿›è¡Œå†³ç­–ï¼ˆå¼‚æ­¥ï¼‰
    messages = [
        SystemMessage(content="ä½ æ˜¯ä¸€ä¸ªæ™ºèƒ½è§„åˆ’è¯„ä¼°åŠ©æ‰‹ï¼Œæ“…é•¿åˆ†ææ‰§è¡Œç»“æœå¹¶åšå‡ºåˆç†å†³ç­–ã€‚"),
        {"role": "user", "content": replan_prompt}
    ]
    
    try:
        result = await q_max.ainvoke(messages)
        
        # è§£æLLMå“åº”
        import json
        import re
        
        decision_data = None
        
        # ç­–ç•¥1: ç›´æ¥è§£æ result.content
        try:
            decision_data = json.loads(result.content)
        except json.JSONDecodeError:
            pass
        
        # ç­–ç•¥2: ä½¿ç”¨æ­£åˆ™æå– JSON å—
        if not decision_data:
            try:
                json_match = re.search(r'\{.*\}', result.content, re.DOTALL)
                if json_match:
                    json_str = json_match.group()
                    # å°è¯•ä¿®å¤å¸¸è§çš„ JSON æ ¼å¼é—®é¢˜
                    # 1. ç§»é™¤ JSON ä¸­çš„æ³¨é‡Š
                    json_str = re.sub(r'//.*?\n|/\*.*?\*/', '', json_str, flags=re.DOTALL)
                    # 2. ç§»é™¤å°¾éšé€—å·
                    json_str = re.sub(r',(\s*[}\]])', r'\1', json_str)
                    decision_data = json.loads(json_str)
            except (json.JSONDecodeError, AttributeError) as e:
                print(f"[Replan] JSON è§£æå¤±è´¥: {e}")
        
        # ç­–ç•¥3: ä½¿ç”¨ LangChain çš„ JsonOutputParser å¼ºåˆ¶è§£æ
        if not decision_data:
            try:
                parser = JsonOutputParser()
                decision_data = parser.invoke(result)
            except Exception as e:
                print(f"[Replan] JsonOutputParser å¤±è´¥: {e}")
        
        # æœ€åçš„å…œåº•: é»˜è®¤ç»§ç»­æ‰§è¡Œ
        if not decision_data:
            print(f"[Replan] æ— æ³•è§£æå“åº”ï¼ŒåŸå§‹å†…å®¹: {result.content[:200]}")
            decision_data = {
                "decision": "continue",
                "reasoning": "æ— æ³•è§£æLLMå“åº”ï¼Œé»˜è®¤ç»§ç»­æ‰§è¡Œ"
            }
        decision = decision_data.get("decision", "continue")
        reasoning = decision_data.get("reasoning", "")
        
        print(f"\n[Replan] å†³ç­–: {decision}")
        print(f"[Replan] æ¨ç†: {reasoning}")
        
        messages_to_add = []
        
        # æ ¹æ®å†³ç­–è¿”å›ä¸åŒçš„ç»“æœ
        if decision == "respond":
            # ä¸å†ç›´æ¥ç”Ÿæˆç­”æ¡ˆï¼Œè·¯ç”±åˆ°ä¸“é—¨çš„ç­”æ¡ˆç”ŸæˆèŠ‚ç‚¹
            routing_message = AIMessage(
                content="ğŸ’¡ å·²æ”¶é›†è¶³å¤Ÿä¿¡æ¯ï¼Œæ­£åœ¨ç”Ÿæˆæœ€ç»ˆç­”æ¡ˆ..."
            )
            messages_to_add.append(routing_message)
            
            return Command(goto="response_generator", update={
                "messages": messages_to_add,
                # æ ‡è®°ä¸ºå®Œæˆï¼Œåœæ­¢ç»§ç»­æ‰§è¡Œè®¡åˆ’
                "current_step": len(plan)
            })
        
        elif decision == "replan":
            # éœ€è¦é‡æ–°è§„åˆ’
            new_plan = decision_data.get("new_plan", [])
            
            replan_message = AIMessage(
                content="ğŸ”„ éœ€è¦è°ƒæ•´è®¡åˆ’\næ–°è®¡åˆ’:\n" +
                        "\n".join([f"{i+1}. {step}" for i, step in enumerate(new_plan)])
            )
            messages_to_add.append(replan_message)
            
            return {
                "plan": new_plan,
                "current_step": 0,  # é‡ç½®åˆ°ç¬¬ä¸€æ­¥
                "messages": messages_to_add
            }
        
        else:  # continue
            # ç»§ç»­æ‰§è¡Œå‰©ä½™è®¡åˆ’
            # ä¸æ·»åŠ æ¶ˆæ¯ï¼Œé¿å…åœ¨å¯¹è¯å†å²ä¸­æ’å…¥è¿‡æ—¶çš„æ¨ç†å†…å®¹
            pass
            
            return {
                "messages": messages_to_add
            }
    
    except Exception as e:
        print(f"[Replan] é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
        
        # å‡ºé”™æ—¶é»˜è®¤ç»§ç»­æ‰§è¡Œ
        error_message = AIMessage(
            content=f"âš ï¸ è¯„ä¼°è¿‡ç¨‹å‡ºé”™ï¼Œç»§ç»­æ‰§è¡ŒåŸè®¡åˆ’\né”™è¯¯: {str(e)[:100]}"
        )
        
        return {
            "messages": [error_message]
        }

